<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Efficient Computing Lab.</title> <meta name="author" content="Jemin Lee"> <meta name="description" content="(*) denotes corresponding authors.&lt;br&gt; (**) denotes equal contributors."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://leejaymin.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Efficient Computing Lab.</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Members</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">(*) denotes corresponding authors.<br> (**) denotes equal contributors.</p> </header> <article> <h2><a href="/publications/" style="color: inherit;">Selected Publications</a></h2> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">WACV</abbr></div> <div id="kim2026iptqvit" class="col-sm-8"> <div class="title">IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers</div> <div class="author"> <a href="https://www.linkedin.com/in/gihwan-kim/?locale=en_US" rel="external nofollow noopener" target="_blank">Gihwan Kim</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026, Round 1 acceptance rate <span class="label label-warning">6.4%</span>, Round 2 acceptance rate <span class="label label-warning">41.1%</span>, Overall acceptance rate <span class="label label-warning">26.4%</span></em>, Feb 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2511.15369" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p></p> </div> </div> </div> </li></ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#1E90FF"><a href="">IEEE TMC</a></abbr></div> <div id="cha2025targetaware" class="col-sm-8"> <div class="title">Target-Aware Neural Network Execution via Compiler-Guided Pruning</div> <div class="author"> JooHyoung Cha, <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a>, <em>Jemin Lee*</em>, <a href="https://netstech.org/sangtaeha/" rel="external nofollow noopener" target="_blank">Sangtae Ha</a>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing (to appear), Accepted, JCR24 IF 9.2 Top 3.29% Nov. 9, 2025, ISSN: 1536-1233</em>, Nov 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/11240555" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>모바일 기기는 이미지 분류나 음성 인식과 같은 다양한 목적을 위해 딥러닝 모델을 실행한다. 그러나 모바일 기기의 자원 제약으로 인해, 연구자들은 모델 프루닝(pruning)을 통해 경량화된 딥 뉴럴 네트워크(DNN) 모델을 만들거나, 컴파일러 최적화를 통해 효율적인 코드를 생성하는 데 주력해 왔다. 하지만 모델 압축과 컴파일러 자동 튜닝(auto-tuning)을 단순히 결합하는 방식은 특정 타깃 장치에서 가장 효율적인 모델을 만들지 못하는 경우가 많음이 관찰되었다. 이 문제를 해결하기 위해 우리는 CPrune을 제안한다. CPrune은 요구되는 정확도를 충족해야 하는 애플리케이션을 지원하기 위해, 타깃 장치 특화 효율적 실행을 위한 컴파일러 기반 정보 활용 모델 프루닝(compiler-informed model pruning) 기법이다. 또한 실제 배포 환경에서의 자원 또는 지연(latency) 제약을 고려하여, 우리는 RB-CPrune을 도입한다. RB-CPrune은 학습된 **지연 예측기(latency estimator)**를 활용해 반복적인 튜닝 과정을 제거한 예측 기반(prdictive) 변형 기법이다. CPrune은 컴파일러 튜닝 과정에서 구축된 서브그래프의 구조적 정보를 기반으로 프루닝을 수행함으로써 경량 DNN 모델을 생성한다. 실험 결과, CPrune은 정확도 요구 조건을 충족하면서도 최첨단 TVM auto-tune 대비 최대 2.73배 빠른 DNN 실행 속도를 달성함을 보여주었다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">CASES</abbr><abbr class="badge award">Artifacts</abbr> </div> <div id="cases25" class="col-sm-8"> <div class="title">Luthier: Bridging Auto-Tuning and Vendor Libraries for Efficient Deep Learning Inference<span class="acm-badges" style="margin-left:8px; white-space:nowrap;"> <img src="/assets/img/badges/artifacts_available_v1_1.png" alt="Artifacts Available" style="height:1em; vertical-align:baseline; margin-right:4px;"> <img src="/assets/img/badges/artifacts_evaluated_functional_v1_1.png" alt="Artifacts Evaluated – Functional" style="height:1em; vertical-align:baseline; margin-right:4px;"> </span> </div> <div class="author"> <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, JooHyoung Cha, Sehyeon Oh, <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://ksp.etri.re.kr/ksp/user/f9caab48-4826-4c7f-b9e8-4fbb8916fc10" rel="external nofollow noopener" target="_blank">Jeman Park</a>, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In ACM International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (ESWEEK CASES 2025) (NRF BK21+ IF: 2, Acceptance Rate 28.2% (20 papers accepted out of 71 submitted)) and ACM Transactions on Embedded Computing Systems (TECS) Vol. 24, No. 5s, pp. 1–23 ISSN:1539-9087, September 29, 2025.</em>, Sep 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/10.1145/3759916" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/Luthier" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/luthier_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/luthier_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3759916"></span> <span class="__dimensions_badge_embed__" data-doi="10.1145/3759916" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>최근 딥러닝 컴파일러는 텐서 프로그래밍에서 최적의 커널 구성을 처음부터 탐색하는 자동 튜닝 방식을 주로 채택하는데, 이는 작업당 수십 시간이 소요되며 비대칭 멀티코어 프로세서에서의 병렬 컴퓨팅에 필수적인 최적화 요소를 간과합니다. 한편 하드웨어 벤더의 수동 최적화 추론 라이브러리는 높은 성능을 제공하지만 신흥 모델에 필요한 유연성과 자동화가 부족합니다. 이러한 격차를 해소하기 위해 우리는 기존 추론 라이브러리에서 최적의 커널을 선별하여 탐색 공간을 크게 축소하고, 비용 모델 기반 프로파일링을 활용해 병렬 컴퓨팅에 가장 효율적인 작업 부하 분배를 신속히 결정하는 Luthier를 제안합니다. 그 결과 Luthier는 ArmNN, AutoTVM, Ansor, ONNXRuntime, TFLite 대비 평균 튜닝 시간을 95% 단축하면서, CPU와 GPU 모두에서 컨볼루션 기반 비전 모델과 트랜스포머 기반 언어 모델(BERT, GPT)에서 최대 2.0배 빠른 실행 속도를 달성합니다. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IJCAI</abbr></div> <div id="lee25ijcai" class="col-sm-8"> <div class="title">Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, Jihun Oh, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>In International Joint Conferences on Artificial Intelligence (IJCAI) Aug. 22, 2025, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19.3%</span> (1042 papers accepted out of 5404 submitted).</em>, Aug 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.24963/ijcai.2025/902" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/eval-quant-llms" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>양자화는 대규모 및 소규모 언어 모델의 비용 효율적 배포를 위한 유망한 해결책으로 주목받고 있습니다. 그러나 기존 연구 대부분은 퍼플렉시티나 기초 지식 작업에 국한되어 있으며 Llama-3.3과 같은 최신 모델에 대한 포괄적 평가가 부족했습니다. 본 논문에서는 10억에서 4050억 매개변수에 이르는 명령어 학습 모델을 대상으로 13개 데이터셋에 걸쳐 4가지 양자화 기법을 적용하여 포괄적 평가를 수행합니다. 우리의 연구 결과는 다음과 같다: (1) 양자화 모델은 일반적으로 더 작은 FP16 기준 모델을 능가하지만, 명령어 수행 및 환각 탐지에서는 종종 어려움을 겪는다; (2) FP8은 모든 작업에서 가장 견고한 옵션으로 꾸준히 나타났으며, 가중치 전용 양자화에서는 AWQ가 GPTQ보다 우수한 성능을 보이는 경향이 있다; (3) 소규모 모델은 4비트 양자화 시 심각한 정확도 하락을 겪을 수 있는 반면, 70B 규모 모델은 안정적인 성능을 유지한다; (4) 특히, 어려운 작업이 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 모델의 본질적 약점을 증폭시키기보다는 가려진 부분을 드러낸다는 점을 시사한다. 4비트 양자화 시 심각한 정확도 하락을 보일 수 있으나, 70B 규모 모델은 안정적인 성능을 유지함; (4) 특히 어려운 과제가 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 단순히 과제 난이도와 상관관계를 가지는 것이 아니라 모델의 내재적 약점을 증폭시킨다는 점을 시사함; (5) LLM 기반 평가 도구(MTBench)는 코딩 및 STEM 과제에서 상당한 성능 저하를 강조하지만, 추론에서는 가끔 개선을 보고함.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LCTES</abbr></div> <div id="lectes25" class="col-sm-8"> <div class="title">Multi-Level Machine Learning-Guided Autotuning for Efficient Code Generation on a Deep Learning Accelerator</div> <div class="author"> JooHyoung Cha, Munyoung Lee, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a> </div> <div class="periodical"> <em>In The 26th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES) Jun. 17, 2025, To appear, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">38%</span> (16 papers accepted out of 42 submitted).</em>, Jun 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3735452.3735538" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>딥 러닝 모델의 복잡성 증가는 특히 딥 러닝 가속기를 위한 특수 하드웨어 및 소프트웨어 최적화를 필요로 합니다. 기계 학습 기반 자동 튜닝 방법이 수동 작업을 줄이는 유망한 해결책으로 부상했지만, 템플릿 기반 및 템플릿 프리 접근법 모두 유효하지 않은 구성 프로파일링으로 인해 튜닝 시간이 길어지는 문제점을 안고 있으며, 이는 런타임 오류로 이어질 수 있습니다. 이 문제를 해결하기 위해 효율성과 견고성을 개선하도록 설계된 다단계 머신 러닝 기반 자동 튜닝 기술인 ML2Tuner를 제안합니다. ML2Tuner는 두 가지 핵심 아이디어를 도입합니다: (1) 프로파일링 전에 무효한 구성을 걸러내는 유효성 예측 모델, (2) 컴파일 과정에서 추출된 숨겨진 특징을 활용하는 고급 성능 예측 모델입니다. 확장된 VTA 가속기에서의 실험 결과, ML2Tuner는 TVM 유사 접근법이 요구하는 샘플의 12.3%만을 사용하여 동등한 성능 향상을 달성하며, 무효 프로파일링 시도를 평균 60.8% 감소시킵니다. 이는 무효 구성을 걸러내어 자동 튜닝 성능을 향상시킬 수 있는 잠재력을 보여줍니다.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IROS</abbr></div> <div id="VisualIROS2024" class="col-sm-8"> <div class="title">Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation</div> <div class="author"> Joonhyung Lee, Sangbeom Park, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://www.linkedin.com/in/minwook-ahn-4a7b6433/?originalSubdomain=kr" rel="external nofollow noopener" target="_blank">Minwook Ahn</a>, and <a href="https://scholar.google.co.kr/citations?user=T3-0OQ8AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Sungjoon Choi</a> </div> <div class="periodical"> <em>In 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024), 14 Oct. 2024</em>, Oct 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2403.11513" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/joonhyung-lee/vpi" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://joonhyung-lee.github.io/vpi/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DAA520"><a href="">ECCV</a></abbr></div> <div id="kim2022cprune" class="col-sm-8"> <div class="title">CPrune: Compiler-informed model pruning for efficient target-aware DNN execution</div> <div class="author"> <a href="https://scholar.google.com/citations?user=A74mynoAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">T. Kim</a>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a>, and <a href="https://netstech.org/sangtaeha/" rel="external nofollow noopener" target="_blank">Sangtae Ha</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV), pp.651–667, Oct. 23-27, 2022, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">28%</span> (1,650 papers accepted out of 5,803 submitted), doi: https://doi.org/10.1007/978-3-031-20044-1_37</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-20044-1_37" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/taehokim20/CPrune" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>모바일 기기에서는 이미지 분류, 음성 인식 등 다양한 목적을 위해 딥러닝 모델이 실행된다. 그러나 모바일 기기의 자원 제약으로 인해 연구자들은 모델 프루닝을 활용하여 경량화된 DNN 모델을 만들거나, 컴파일러 최적화를 통해 효율적인 코드를 생성하는 것에 주로 집중해 왔다. 놀랍게도, 우리는 모델 압축과 컴파일러 자동 튜닝(auto-tuning)을 단순히 결합하는 방식이 특정 타깃 장치에서 가장 효율적인 모델을 생성하지 못하는 경우가 많다는 사실을 발견했다. 이 문제를 해결하기 위해, 우리는 CPrune을 제안한다. CPrune은 목표 정확도를 충족해야 하는 애플리케이션을 지원하기 위해 타깃 장치에 최적화된 DNN 실행을 가능하게 하는 컴파일러 기반 정보 활용 프루닝(compiler-informed model pruning) 기법이다. CPrune은 컴파일러 튜닝 과정에서 생성되는 서브그래프의 구조적 정보를 기반으로 프루닝을 수행하여 경량화된 DNN 모델을 만든다. 실험 결과, CPrune은 정확도 요구 조건을 충족하면서도 최첨단 TVM auto-tune 대비 최대 2.73배 빠른 DNN 실행 속도를 달성하였다.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#1E90FF"><a href="">IEEE TMC</a></abbr></div> <div id="lee2019pass" class="col-sm-8"> <div class="title">PASS: Reducing redundant notifications between a smartphone and a smartwatch for energy saving</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://ic.kaist.ac.kr/members" rel="external nofollow noopener" target="_blank">Uichin Lee</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing,(impact factor: 5.538, JCR20: Top 17%, telecommunications rank #16 out of 91), ISSN: 1536-1233, doi: https://doi.org/10.1109/TMC.2019.2930506</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TMC.2019.2930506" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/leejaymin/nCollector" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC143C"><a href="">MobiCom</a></abbr></div> <div id="kang2019fire2" class="col-sm-8"> <div class="title">Fire in your hands: Understanding thermal behavior of smartphones</div> <div class="author"> <a href="https://scholar.google.com/citations?user=B9HMz0EAAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Soowon Kang</a>, Hyeonwoo Choi, Sooyoung Park, <a href="http://cjpark.xyz/" rel="external nofollow noopener" target="_blank">Chunjong Park</a>, <em>Jemin Lee</em>, <a href="https://ic.kaist.ac.kr/members" rel="external nofollow noopener" target="_blank">Uichin Lee</a>, and <a href="https://sites.google.com/site/wewantsj/" rel="external nofollow noopener" target="_blank">Sung-Ju Lee</a> </div> <div class="periodical"> <em>In The 25th Annual International Conference on Mobile Computing and Networking, pp. 1-16, Los Cabos, Mexico, 21-25 Oct. 2019, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19%</span> (55 papers accepted out of 290 submitted).</em>, Oct 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://dl.acm.org/citation.cfm?id=3300128" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://nmsl.kaist.ac.kr/projects/thermal/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> </div> <h2>All Peer-reviewed Journals and Proceedings</h2> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#CD853F"><a href="">FGCS</a></abbr></div> <div id="kim2025fgcs" class="col-sm-8"> <div class="title">Towards an Efficient Dataflow-flexible Accelerator by Finding Optimal Dataflows of DNNs</div> <div class="author"> Hyunjun Kim, Whoi Ree Ha, Yongseok Lee, Dongju Lee, Jongwon Lee, Deumji Woo, <em>Jemin Lee</em>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and Yunheung Paek</div> <div class="periodical"> <em>Future Generation Computer Systems, 1 Mar 2026, 108123, JCR24 IF 6.1 Top 9.86%, ISSN: 0167-739X</em>, Mar 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.future.2025.108123" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>이 논문은 여러 딥 뉴럴 네트워크(DNN) 모델의 연산을 처리하는 데 기존 이종 데이터플로우 가속기(Heterogeneous Dataflow Accelerator, HDA)가 갖는 한계를 해결하기 위한 새로운 데이터플로우 유연형 가속기 설계를 제안한다. 제안된 설계는 기존 연구와 비교하여 더 높은 데이터플로우 유연성과 향상된 효율성을 제공한다. 가속기는 대표적인 데이터플로우를 일정 수만큼 **운영 모드(operating mode)**로 고정적으로 구현하며, 이들 간을 동적으로 전환해가며 연산을 수행한다. 또한 설계 탐색(DSE, Design Space Exploration) 도구를 활용해 후보 데이터플로우들의 효율성을 평가하고, 최적의 운영 모드 수와 구성 유형을 결정한다. 대상 DNN 모델의 각 레이어는 다양한 운영 모드를 적용해 평가되며, 레이어별로 최적의 운영 모드를 선택하게 된다. 추가적으로, 다수의 데이터플로우를 지원하면서 발생하는 오버헤드를 줄이기 위해 두 가지 최적화 기법이 도입된다. 첫 번째 기법은 데이터플로우 전환 횟수를 최소화해 전환 시 발생하는 큰 오버헤드를 줄이는 것이다. 두 번째 기법은 여러 데이터플로우를 지원하기 위해 필요한 하드웨어 구성 요소들 중 중복되는 부분을 식별하고 재사용을 극대화하는 것이다. 이를 통해 데이터플로우 유연형 가속기 설계에서 중요한 문제인 칩 면적 증가를 최소화한다. 실험 결과, 제안된 알고리즘은 높은 효율을 유지하면서 더 큰 데이터플로우 유연성을 제공함을 보였다. HDA와 비교했을 때, 본 설계는 평균 34.6%의 지연(latency) 감소를 달성하면서도 칩 면적은 6.4% 증가, 에너지 오버헤드는 무시할 수준에 그쳤다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">WACV</abbr></div> <div id="kim2026iptqvit" class="col-sm-8"> <div class="title">IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers</div> <div class="author"> <a href="https://www.linkedin.com/in/gihwan-kim/?locale=en_US" rel="external nofollow noopener" target="_blank">Gihwan Kim</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026, Round 1 acceptance rate <span class="label label-warning">6.4%</span>, Round 2 acceptance rate <span class="label label-warning">41.1%</span>, Overall acceptance rate <span class="label label-warning">26.4%</span></em>, Feb 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2511.15369" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p></p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#1E90FF"><a href="">IEEE TMC</a></abbr></div> <div id="cha2025targetaware" class="col-sm-8"> <div class="title">Target-Aware Neural Network Execution via Compiler-Guided Pruning</div> <div class="author"> JooHyoung Cha, <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a>, <em>Jemin Lee*</em>, <a href="https://netstech.org/sangtaeha/" rel="external nofollow noopener" target="_blank">Sangtae Ha</a>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing (to appear), Accepted, JCR24 IF 9.2 Top 3.29% Nov. 9, 2025, ISSN: 1536-1233</em>, Nov 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/11240555" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>모바일 기기는 이미지 분류나 음성 인식과 같은 다양한 목적을 위해 딥러닝 모델을 실행한다. 그러나 모바일 기기의 자원 제약으로 인해, 연구자들은 모델 프루닝(pruning)을 통해 경량화된 딥 뉴럴 네트워크(DNN) 모델을 만들거나, 컴파일러 최적화를 통해 효율적인 코드를 생성하는 데 주력해 왔다. 하지만 모델 압축과 컴파일러 자동 튜닝(auto-tuning)을 단순히 결합하는 방식은 특정 타깃 장치에서 가장 효율적인 모델을 만들지 못하는 경우가 많음이 관찰되었다. 이 문제를 해결하기 위해 우리는 CPrune을 제안한다. CPrune은 요구되는 정확도를 충족해야 하는 애플리케이션을 지원하기 위해, 타깃 장치 특화 효율적 실행을 위한 컴파일러 기반 정보 활용 모델 프루닝(compiler-informed model pruning) 기법이다. 또한 실제 배포 환경에서의 자원 또는 지연(latency) 제약을 고려하여, 우리는 RB-CPrune을 도입한다. RB-CPrune은 학습된 **지연 예측기(latency estimator)**를 활용해 반복적인 튜닝 과정을 제거한 예측 기반(prdictive) 변형 기법이다. CPrune은 컴파일러 튜닝 과정에서 구축된 서브그래프의 구조적 정보를 기반으로 프루닝을 수행함으로써 경량 DNN 모델을 생성한다. 실험 결과, CPrune은 정확도 요구 조건을 충족하면서도 최첨단 TVM auto-tune 대비 최대 2.73배 빠른 DNN 실행 속도를 달성함을 보여주었다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CASES</abbr></div> <div id="caseswip2025" class="col-sm-8"> <div class="title">I-FlashAttention: Fully Integer Fused Attention for Efficient Vision Transformers (WIP)</div> <div class="author"> Sehyeon Oh, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In ACM International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (ESWEEK CASES 2025), Acceptance Rate 57.1% (4 papers accepted out of 7 invited) September 30, 2025.</em>, Sep 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1145/3742872.3757072" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">CASES</abbr><abbr class="badge award">Artifacts</abbr> </div> <div id="cases25" class="col-sm-8"> <div class="title">Luthier: Bridging Auto-Tuning and Vendor Libraries for Efficient Deep Learning Inference<span class="acm-badges" style="margin-left:8px; white-space:nowrap;"> <img src="/assets/img/badges/artifacts_available_v1_1.png" alt="Artifacts Available" style="height:1em; vertical-align:baseline; margin-right:4px;"> <img src="/assets/img/badges/artifacts_evaluated_functional_v1_1.png" alt="Artifacts Evaluated – Functional" style="height:1em; vertical-align:baseline; margin-right:4px;"> </span> </div> <div class="author"> <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, JooHyoung Cha, Sehyeon Oh, <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://ksp.etri.re.kr/ksp/user/f9caab48-4826-4c7f-b9e8-4fbb8916fc10" rel="external nofollow noopener" target="_blank">Jeman Park</a>, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In ACM International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (ESWEEK CASES 2025) (NRF BK21+ IF: 2, Acceptance Rate 28.2% (20 papers accepted out of 71 submitted)) and ACM Transactions on Embedded Computing Systems (TECS) Vol. 24, No. 5s, pp. 1–23 ISSN:1539-9087, September 29, 2025.</em>, Sep 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/10.1145/3759916" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/Luthier" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/luthier_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/luthier_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3759916"></span> <span class="__dimensions_badge_embed__" data-doi="10.1145/3759916" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>최근 딥러닝 컴파일러는 텐서 프로그래밍에서 최적의 커널 구성을 처음부터 탐색하는 자동 튜닝 방식을 주로 채택하는데, 이는 작업당 수십 시간이 소요되며 비대칭 멀티코어 프로세서에서의 병렬 컴퓨팅에 필수적인 최적화 요소를 간과합니다. 한편 하드웨어 벤더의 수동 최적화 추론 라이브러리는 높은 성능을 제공하지만 신흥 모델에 필요한 유연성과 자동화가 부족합니다. 이러한 격차를 해소하기 위해 우리는 기존 추론 라이브러리에서 최적의 커널을 선별하여 탐색 공간을 크게 축소하고, 비용 모델 기반 프로파일링을 활용해 병렬 컴퓨팅에 가장 효율적인 작업 부하 분배를 신속히 결정하는 Luthier를 제안합니다. 그 결과 Luthier는 ArmNN, AutoTVM, Ansor, ONNXRuntime, TFLite 대비 평균 튜닝 시간을 95% 단축하면서, CPU와 GPU 모두에서 컨볼루션 기반 비전 모델과 트랜스포머 기반 언어 모델(BERT, GPT)에서 최대 2.0배 빠른 실행 속도를 달성합니다. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICCV W.</abbr></div> <div id="acvr25_1" class="col-sm-8"> <div class="title">Design Practices and Lessons from Deploying On-device Vision-Language Interaction in Robotic Guide Dogs</div> <div class="author"> <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <em>Jemin Lee*</em>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>In ICCV Workshop ACVR 2025</em>, Jul 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/ICCV2025W/ACVR/papers/Kwon_Design_Practices_and_Lessons_from_Deploying_On-device_Vision-Language_Interaction_in_ICCVW_2025_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICCV W.</abbr></div> <div id="acvr25_2" class="col-sm-8"> <div class="title">TriPlanNet: Triangle Path Planning Network for A Variable Truss Robot with Deep Learning</div> <div class="author"> Choonghan Lee, Leah Harris, Sehyeon Oh, Juhyung Cha, <em>Jemin Lee</em>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and Andrew Jang-ho Bae</div> <div class="periodical"> <em>In ICCV Workshop ACVR 2025</em>, Jul 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/ICCV2025W/ACVR/papers/Lee_TriPlanNet_Triangle_Path_Planning_Network_for_A_Variable_Truss_Robot_ICCVW_2025_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00369f"><a href="">Preprint</a></abbr></div> <div id="lee25survey" class="col-sm-8"> <div class="title">A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency</div> <div class="author"> <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, Sungryeol Jeon, Chaelyn Lee, Seokhun Jeon, Byung-Soo Kim, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In Preprint on ArXiv 2505.01658 May 3, 2025</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2505.01658" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/sihyeong/Awesome-LLM-Inference-Engine" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IJCAI</abbr></div> <div id="lee25ijcai" class="col-sm-8"> <div class="title">Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, Jihun Oh, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>In International Joint Conferences on Artificial Intelligence (IJCAI) Aug. 22, 2025, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19.3%</span> (1042 papers accepted out of 5404 submitted).</em>, Aug 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.24963/ijcai.2025/902" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/eval-quant-llms" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>양자화는 대규모 및 소규모 언어 모델의 비용 효율적 배포를 위한 유망한 해결책으로 주목받고 있습니다. 그러나 기존 연구 대부분은 퍼플렉시티나 기초 지식 작업에 국한되어 있으며 Llama-3.3과 같은 최신 모델에 대한 포괄적 평가가 부족했습니다. 본 논문에서는 10억에서 4050억 매개변수에 이르는 명령어 학습 모델을 대상으로 13개 데이터셋에 걸쳐 4가지 양자화 기법을 적용하여 포괄적 평가를 수행합니다. 우리의 연구 결과는 다음과 같다: (1) 양자화 모델은 일반적으로 더 작은 FP16 기준 모델을 능가하지만, 명령어 수행 및 환각 탐지에서는 종종 어려움을 겪는다; (2) FP8은 모든 작업에서 가장 견고한 옵션으로 꾸준히 나타났으며, 가중치 전용 양자화에서는 AWQ가 GPTQ보다 우수한 성능을 보이는 경향이 있다; (3) 소규모 모델은 4비트 양자화 시 심각한 정확도 하락을 겪을 수 있는 반면, 70B 규모 모델은 안정적인 성능을 유지한다; (4) 특히, 어려운 작업이 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 모델의 본질적 약점을 증폭시키기보다는 가려진 부분을 드러낸다는 점을 시사한다. 4비트 양자화 시 심각한 정확도 하락을 보일 수 있으나, 70B 규모 모델은 안정적인 성능을 유지함; (4) 특히 어려운 과제가 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 단순히 과제 난이도와 상관관계를 가지는 것이 아니라 모델의 내재적 약점을 증폭시킨다는 점을 시사함; (5) LLM 기반 평가 도구(MTBench)는 코딩 및 STEM 과제에서 상당한 성능 저하를 강조하지만, 추론에서는 가끔 개선을 보고함.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LCTES</abbr></div> <div id="lectes25" class="col-sm-8"> <div class="title">Multi-Level Machine Learning-Guided Autotuning for Efficient Code Generation on a Deep Learning Accelerator</div> <div class="author"> JooHyoung Cha, Munyoung Lee, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a> </div> <div class="periodical"> <em>In The 26th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES) Jun. 17, 2025, To appear, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">38%</span> (16 papers accepted out of 42 submitted).</em>, Jun 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3735452.3735538" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>딥 러닝 모델의 복잡성 증가는 특히 딥 러닝 가속기를 위한 특수 하드웨어 및 소프트웨어 최적화를 필요로 합니다. 기계 학습 기반 자동 튜닝 방법이 수동 작업을 줄이는 유망한 해결책으로 부상했지만, 템플릿 기반 및 템플릿 프리 접근법 모두 유효하지 않은 구성 프로파일링으로 인해 튜닝 시간이 길어지는 문제점을 안고 있으며, 이는 런타임 오류로 이어질 수 있습니다. 이 문제를 해결하기 위해 효율성과 견고성을 개선하도록 설계된 다단계 머신 러닝 기반 자동 튜닝 기술인 ML2Tuner를 제안합니다. ML2Tuner는 두 가지 핵심 아이디어를 도입합니다: (1) 프로파일링 전에 무효한 구성을 걸러내는 유효성 예측 모델, (2) 컴파일 과정에서 추출된 숨겨진 특징을 활용하는 고급 성능 예측 모델입니다. 확장된 VTA 가속기에서의 실험 결과, ML2Tuner는 TVM 유사 접근법이 요구하는 샘플의 12.3%만을 사용하여 동등한 성능 향상을 달성하며, 무효 프로파일링 시도를 평균 60.8% 감소시킵니다. 이는 무효 구성을 걸러내어 자동 튜닝 성능을 향상시킬 수 있는 잠재력을 보여줍니다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#CD853F"><a href="">FGCS</a></abbr></div> <div id="QuantuneV2" class="col-sm-8"> <div class="title">QuantuneV2: Compiler-based local metric-driven mixed precision quantization for practical embedded AI applications</div> <div class="author"> <a href="https://www.deal.kaist.ac.kr/members/ph-d-student" rel="external nofollow noopener" target="_blank">Jeongseok Kim**</a>, <em>Jemin Lee**</em>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and <a href="https://www.deal.kaist.ac.kr/members/director" rel="external nofollow noopener" target="_blank">Daeyoung Kim</a> </div> <div class="periodical"> <em>In Future Generation Computer Systems Volume 166, May 1, 2025, 107718 (JCR24 IF: 6.1, Top 9.86%, Q1), ISSN: 0167-739X</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.future.2025.107718" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>혼합 정밀도 양자화 기법은 정확도 저하를 최소화하면서 모델 크기를 줄이기 위해 제안되어 왔다. 그러나 기존 연구들은 재학습이 필요하며, 컴파일 과정에서 발생하는 계산 오버헤드와 중간 표현(IR)을 고려하지 않아 컴파일러 수준에서의 적용에 한계가 있다. 여기서 말하는 계산 오버헤드는 추론 과정에서 빈번하게 수행되는 양자화 및 비양자화 연산으로 인해 발생하는 런타임 지연을 의미한다. 이러한 연산을 개별 연산자 단위로 수행할 경우 런타임이 크게 증가한다. 이 문제를 해결하기 위해, 우리는 실질적인 임베디드 AI 응용을 위해 설계된 컴파일러 기반 혼합 정밀도 양자화 방법인 QuantuneV2를 제안한다. QuantuneV2는 양자화 전과 양자화 후 단 두 번만 추론을 수행하며, 모델 파라미터 수에 비례해 선형적으로 증가하는 계산 복잡도를 가진다. 또한 가중치, 활성값, 신호대양자화잡음비(SQNR), 평균제곱오차(MSE)와 같은 로컬 메트릭을 활용하여 민감도 분석을 더욱 안정적으로 만들었다. 아울러 최적의 IR을 선택하고 연산자 융합(operator fusion)을 적용하여 계산 오버헤드를 줄였다. 실험 결과, QuantuneV2는 ResNet18v1, ResNet50v1, SqueezeNetv1, VGGNet, MobileNetv2 등 다섯 가지 모델에서 기존 방법 대비 최대 10.28%의 정확도 향상과 12.52%의 속도 향상을 달성했다. 이는 QuantuneV2가 계산 효율성을 유지하면서 모델 성능을 향상시켜 임베디드 AI 환경에 적합함을 보여준다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Sensors</abbr><abbr class="badge award">Invited</abbr> </div> <div id="sensors25" class="col-sm-8"> <div class="title">Optimizing Real-Time Object Detection in a Multi NPU Systems</div> <div class="author"> Sehyeon Oh, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In MDPI Sensors, Volume 25, Issue 5, pp. 1376 March 1 2025 EISSN 1424-8220 (JCR23 IF: 3.4, JCR23 Top 30.9%, Q2)</em>, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/s25051376" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>실시간 객체 탐지는 높은 처리량과 낮은 지연 시간을 요구하므로, 하드웨어 가속기의 사용이 필수적이다. NPU는 딥러닝 모델 계산을 가속하기 위해 설계된 특수 하드웨어로, 기존 CPU나 GPU보다 더 높은 에너지 효율과 병렬 처리 성능을 제공한다. 특히 실시간 처리가 필요한 애플리케이션에서 지연 시간을 줄이고 처리 속도를 향상시키는 데 중요한 역할을 한다. 본 논문에서는 YOLOv3 기반의 실시간 객체 탐지 시스템을 구축하고, Neubla의 Antara NPU를 활용하여 성능 최적화를 위한 두 가지 접근법을 제안한다. 첫째, 더블 버퍼링(double buffering)을 통해 CPU가 데이터를 미리 처리하도록 하여 NPU 추론의 연속성을 확보한다. 둘째, 다중 NPU 환경에서 큐(queue) 기반 처리 방식으로 작업을 NPU 간에 분배하며, 암달의 법칙(Amdahl’s law)을 이용해 성능 한계를 분석한다. 실험 결과, CPU만 사용하는 환경과 비교했을 때, 단일 버퍼링(single buffering)에서 NPU를 적용하면 처리량이 2.13배 향상되었고, 더블 버퍼링에서는 3.35배, 다중 NPU 환경에서는 4.81배 향상되었다. 지연 시간(latency)은 단일 및 더블 버퍼링 환경에서 1.6배, 다중 NPU 환경에서 1.18배 감소하였다. 정확도는 CPU에서 31.4 mAP, NPU에서 31.8 mAP로 거의 동일하게 유지되었다.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">AIcompS</abbr><abbr class="badge award">Distinguished</abbr> </div> <div id="AIcompS24oh" class="col-sm-8"> <div class="title">Optimizing Real-Time Object Detection in a Multi NPU System with Double Buffering and Queue-Based Processing</div> <div class="author"> Sehyeon Oh, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In The 1st International Conference on Artificial Intelligence Computing and Systems</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://leejaymin.github.io/assets/pdf/aicomps_oh.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">AIcompS</abbr></div> <div id="AIcompS24park" class="col-sm-8"> <div class="title">A Review on Proprietary Accelerators for Large Language Models</div> <div class="author"> <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <em>Jemin Lee</em>, Byung-Soo Kim, and Seokhun Jeon</div> <div class="periodical"> <em>In The 1st International Conference on Artificial Intelligence Computing and Systems</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aicomps.kips.or.kr/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS W.</abbr></div> <div id="ml2tuner" class="col-sm-8"> <div class="title">ML^2Tuner: Efficient Code Tuning via Multi-Level Machine Learning Models</div> <div class="author"> JooHyoung Cha, Munyoung Lee, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, Jubin Lee, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a> </div> <div class="periodical"> <em>In Machine Learning for Systems Workshop at NeurIPS</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://mlforsystems.org/assets/papers/neurips2024/paper6.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IEEE IoT J.</abbr></div> <div id="jemin2024Qhyvit" class="col-sm-8"> <div class="title">Q-HyViT: Post-Training Quantization for Hybrid Vision Transformer with Bridge Block Reconstruction for IoT Systems</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://ksp.etri.re.kr/ksp/user/f9caab48-4826-4c7f-b9e8-4fbb8916fc10" rel="external nofollow noopener" target="_blank">Jeman Park</a>, and <a href="https://songhwanjun.github.io/" rel="external nofollow noopener" target="_blank">Hwanjun Song</a> </div> <div class="periodical"> <em>IEEE Internet of Things Journal Vol. 11, Issue 22, pp.36384-36396, ISSN: 2327-4662, Nov. 15, 2024 (JCR24 IF: 8.9 Top 4.07%)</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/JIOT.2024.3403844" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/q-hyvit" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>최근 비전 트랜스포머(ViT)는 분류, 탐지, 세분화 등 다양한 응용 분야에서 합성곱 신경망(CNN)을 대체하며 뛰어난 성능을 보이고 있다. 그러나 ViT의 높은 계산 요구량은 광범위한 활용을 어렵게 만든다. 이러한 문제를 해결하기 위해 연구자들은 합성곱 레이어와 트랜스포머 레이어를 결합하고, 선형 복잡도의 최적화된 어텐션 계산을 사용하는 효율적인 하이브리드 트랜스포머 아키텍처를 제안해 왔다. 또한 사후학습 양자화(PTQ)가 계산 부담을 줄이는 방법으로 제시되었다. 모바일 장치에서 ViT의 최적 가속을 달성하려면 양자화 기법과 효율적인 하이브리드 트랜스포머 구조를 전략적으로 통합해야 한다. 그러나 지금까지 효율적인 하이브리드 트랜스포머에 양자화를 적용한 연구는 없었다. 이 논문에서는 기존의 ViT용 PTQ 기법을 효율적인 하이브리드 트랜스포머에 적용할 경우 정확도가 크게 떨어진다는 사실을 발견했으며, 이는 매우 동적인 값 범위, 제로포인트 오버플로, 다양한 정규화 방식, 5M 미만의 제한된 모델 파라미터 수 등 네 가지 문제 때문이라고 밝힌다. 이러한 문제를 해결하기 위해 우리는 새로운 PTQ 기법을 제안하며, 이는 MobileViTv1, MobileViTv2, Mobile-Former, EfficientFormerV1, EfficientFormerV2 등 효율적인 하이브리드 ViT를 최초로 양자화한 방법이다. 우리 방법은 기존 PTQ 기법(EasyQuant, FQ-ViT, PTQ4ViT, RepQ-ViT) 대비 8비트에서 평균 17.73%, 6비트에서 평균 29.75%의 성능 향상을 달성했다. 코드는 https://gitlab.com/ones-ai/q-hyvit 에서 공개할 예정이다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ETRI J.</abbr></div> <div id="park2024etri" class="col-sm-8"> <div class="title">NEST-C: A Deep Learning Compiler Framework for Heterogeneous Computing Systems with AI Accelerators</div> <div class="author"> <a href="https://ksp.etri.re.kr/ksp/user/f9caab48-4826-4c7f-b9e8-4fbb8916fc10" rel="external nofollow noopener" target="_blank">Jeman Park</a>, <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <a href="https://www.linkedin.com/in/junmo-park-82188b76/?originalSubdomain=kr" rel="external nofollow noopener" target="_blank">Junmo Park</a>, <em>Jemin Lee*</em>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>In ETRI Journal Vol. 46 Issue 5, pp.851-864 ISSN: 1225-6463 (JCR24 IF 1.6, 70%) Oct. 28, 2024</em>, Oct 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.4218/etrij.2024-0139" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/nest-compiler" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>딥 러닝(DL)은 인공 지능(AI)을 크게 발전시켰으나, PyTorch, ONNX, TensorFlow와 같은 프레임워크는 범용 GPU에 최적화되어 있어 신경 처리 장치(NPU) 및 메모리 내 처리(PIM) 장치와 같은 특수 가속기에서 비효율적입니다. 이러한 가속기는 처리량과 에너지 효율을 모두 최적화하도록 설계되었지만, 보다 맞춤화된 최적화가 필요합니다. 이러한 한계를 해결하기 위해 우리는 다양한 AI 가속기에서 모델 배포 및 성능을 개선하는 새로운 DL 프레임워크인 NEST 컴파일러(NEST-C)를 제안합니다. NEST-C는 프로파일링 기반 양자화, 동적 그래프 분할, 다단계 중간 표현(IR) 통합을 활용하여 다양한 하드웨어 플랫폼에서 효율적인 실행을 가능하게 합니다. 연구 결과 NEST-C는 다양한 AI 가속기에서 계산 효율성과 적응성을 크게 향상시켜 더 높은 처리량, 낮은 지연 시간, 개선된 자원 활용도, 향상된 모델 이식성을 달성합니다. 이러한 이점은 현대 AI 애플리케이션에서 더 효율적인 DL 모델 배포에 기여합니다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECCV W.</abbr></div> <div id="gihwan2024Eccv" class="col-sm-8"> <div class="title">Mixed Non-linear Quantization for Vision Transformers</div> <div class="author"> <a href="https://www.linkedin.com/in/gihwan-kim/?locale=en_US" rel="external nofollow noopener" target="_blank">Gihwan Kim**</a>, <em>Jemin Lee**</em>, <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In ECCV Workshop CADL</em>, Sep 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2407.18437" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/mixed-non-linear-quantization" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IROS</abbr></div> <div id="VisualIROS2024" class="col-sm-8"> <div class="title">Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation</div> <div class="author"> Joonhyung Lee, Sangbeom Park, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://www.linkedin.com/in/minwook-ahn-4a7b6433/?originalSubdomain=kr" rel="external nofollow noopener" target="_blank">Minwook Ahn</a>, and <a href="https://scholar.google.co.kr/citations?user=T3-0OQ8AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Sungjoon Choi</a> </div> <div class="periodical"> <em>In 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024), 14 Oct. 2024</em>, Oct 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2403.11513" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/joonhyung-lee/vpi" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://joonhyung-lee.github.io/vpi/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IEEE ESL</abbr></div> <div id="kwon2023pipelining" class="col-sm-8"> <div class="title">Pipelining of a Mobile SoC and an External NPU for Accelerating CNN Inference</div> <div class="author"> <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>IEEE Embedded Systems Letters, Vol. 16 Issue 2 pp. 150-153, June 2024 ISSN 1943-0663 (JCR24 IF 2, 55.08), doi: https://doi.org/10.1109/LES.2023.3305016</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/LES.2023.3305016" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>하드웨어와 소프트웨어의 공동 발전에 따라 컨볼루션 신경망(CNN) 알고리즘이 에지 디바이스에 점점 더 많이 배포되고 있습니다. 리소스가 제한된 디바이스에 CNN을 배포하려면 종종 CPU와 GPU의 최적화가 필요합니다. 신경망 처리 장치(NPU)와 같은 전용 하드웨어가 성공적으로 도입되었지만, CPU, GPU 및 NPU 간의 협력적 방법은 아직 미성숙한 상태입니다. 본 논문에서는 모바일 시스템온칩(SoC)과 외부 NPU(eNPU)의 통합을 최적화하여 조화로운 파이프라이닝을 달성하고 추론 속도 및 처리량을 향상시키기 위한 두 가지 접근법을 제안한다. 첫 번째 접근법은 호스트 측에서 레이어별 최적 라이브러리를 할당하기 위한 기본 선형 대수 서브프로그램 라이브러리 검색 방식을 포함하며, 두 번째 접근법은 모델 슬라이스 포인트를 탐색하여 성능을 최적화한다. 자동 할당되는 계산 라이브러리로 CPU 기반 NNPACK, OpenBLAS 및 GPU 기반 CLBlast를 활용합니다. 전체 신경망(NN)은 NN 레이어 특성과 하드웨어 성능을 기반으로 두 부분으로 최적 분할됩니다. Hikey-970, Hikey-960, Firefly-rk3399 등 다양한 모바일 기기에서 알고리즘을 평가했습니다. 실험을 통해 제안된 파이프라인 추론 방식이 eNPU 및 SoC에서의 병렬 실행 대비 지연 시간을 10% 감소시키고 처리량을 17% 이상 증가시킨다는 점을 입증했습니다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICRA W.</abbr></div> <div id="VisualICRAW" class="col-sm-8"> <div class="title">Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation</div> <div class="author"> Joonhyung Lee, Sangbeom Park, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://www.linkedin.com/in/minwook-ahn-4a7b6433/?originalSubdomain=kr" rel="external nofollow noopener" target="_blank">Minwook Ahn</a>, and <a href="https://scholar.google.co.kr/citations?user=T3-0OQ8AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Sungjoon Choi</a> </div> <div class="periodical"> <em>In First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/forum?id=D2e4URvhpP" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS W.</abbr></div> <div id="acltuner" class="col-sm-8"> <div class="title">ACLTuner: A Profiling-Driven Fast Tuning to Optimize Deep Learning Inference</div> <div class="author"> <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, Joo Hyoung Cha, Jubin Lee, <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://ksp.etri.re.kr/ksp/user/f9caab48-4826-4c7f-b9e8-4fbb8916fc10" rel="external nofollow noopener" target="_blank">Jeman Park</a>, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In Machine Learning for Systems Workshop at NeurIPS</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/pdf?id=k0FIPHpeR4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ETRI J.</abbr></div> <div id="yu2023partitiontuner" class="col-sm-8"> <div class="title">PartitionTuner: An operator scheduler for deep-learning compilers supporting multiple heterogeneous processing units</div> <div class="author"> <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://ksp.etri.re.kr/ksp/user/f9caab48-4826-4c7f-b9e8-4fbb8916fc10" rel="external nofollow noopener" target="_blank">Jeman Park</a>, <a href="https://www.linkedin.com/in/junmo-park-82188b76/?originalSubdomain=kr" rel="external nofollow noopener" target="_blank">Junmo Park</a>, and <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a> </div> <div class="periodical"> <em>ETRI Journal Vol. 45 No. 2, Apr. 20, 2023 (JCR23 IF: 1.3) ISSN: 1225-6463, doi: https://doi.org/10.4218/etrij.2021-0446</em>, Apr 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.4218/etrij.2021-0446" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>최근 모바일 플랫폼과 같은 임베디드 시스템은 중앙 처리 장치(CPU)와 신경망 처리 장치(NPU) 등 병렬로 작동할 수 있는 다중 처리 장치를 갖추고 있습니다. 딥 러닝 컴파일러를 활용하면 딥 신경망(DNN)으로부터 이러한 임베디드 시스템에 최적화된 기계 코드를 생성할 수 있습니다. 그러나 지금까지 제안된 딥러닝 컴파일러는 단일 처리 장치에서 DNN 연산자를 순차적으로 실행하는 코드나 그래픽 처리 장치(GPU)용 병렬 코드만을 생성합니다. 본 연구에서는 CPU와 NPU를 포함한 다중 이종 처리 장치(PU)를 지원하는 딥러닝 컴파일러용 연산자 스케줄러인 PartitionTuner를 제안합니다. PartitionTuner는 전체 DNN 추론 시간을 최소화하기 위해 사용 가능한 모든 PU를 동시에 활용하는 연산자 스케줄링 계획을 생성할 수 있습니다. 연산자 스케줄링은 DNN 아키텍처 분석과 이종 처리 장치에서 측정된 개별 및 그룹 연산자의 성능 프로파일을 기반으로 합니다. 7개 DNN에 대한 실험 결과, PartitionTuner는 SqueezeNet에 대해 정적 타입 기반 연산자 스케줄링 기법보다 5.03% 더 우수한 성능을 보이는 스케줄링 계획을 생성합니다. 또한 PartitionTuner는 ResNet50, ResNet18, SqueezeNet에 대해 각각 7.18%, 5.36%, 2.73%로 최근 프로파일링 기반 연산자 스케줄링 기법보다 우수한 성능을 보입니다.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DAA520"><a href="">ECCV</a></abbr></div> <div id="kim2022cprune" class="col-sm-8"> <div class="title">CPrune: Compiler-informed model pruning for efficient target-aware DNN execution</div> <div class="author"> <a href="https://scholar.google.com/citations?user=A74mynoAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">T. Kim</a>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a>, and <a href="https://netstech.org/sangtaeha/" rel="external nofollow noopener" target="_blank">Sangtae Ha</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV), pp.651–667, Oct. 23-27, 2022, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">28%</span> (1,650 papers accepted out of 5,803 submitted), doi: https://doi.org/10.1007/978-3-031-20044-1_37</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-20044-1_37" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/taehokim20/CPrune" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>모바일 기기에서는 이미지 분류, 음성 인식 등 다양한 목적을 위해 딥러닝 모델이 실행된다. 그러나 모바일 기기의 자원 제약으로 인해 연구자들은 모델 프루닝을 활용하여 경량화된 DNN 모델을 만들거나, 컴파일러 최적화를 통해 효율적인 코드를 생성하는 것에 주로 집중해 왔다. 놀랍게도, 우리는 모델 압축과 컴파일러 자동 튜닝(auto-tuning)을 단순히 결합하는 방식이 특정 타깃 장치에서 가장 효율적인 모델을 생성하지 못하는 경우가 많다는 사실을 발견했다. 이 문제를 해결하기 위해, 우리는 CPrune을 제안한다. CPrune은 목표 정확도를 충족해야 하는 애플리케이션을 지원하기 위해 타깃 장치에 최적화된 DNN 실행을 가능하게 하는 컴파일러 기반 정보 활용 프루닝(compiler-informed model pruning) 기법이다. CPrune은 컴파일러 튜닝 과정에서 생성되는 서브그래프의 구조적 정보를 기반으로 프루닝을 수행하여 경량화된 DNN 모델을 만든다. 실험 결과, CPrune은 정확도 요구 조건을 충족하면서도 최첨단 TVM auto-tune 대비 최대 2.73배 빠른 DNN 실행 속도를 달성하였다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Access</abbr></div> <div id="park2022software" class="col-sm-8"> <div class="title">Software-Level Memory Regulation to Reduce Execution Time Variation on Multicore Real-Time Systems</div> <div class="author"> <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>IEEE Access Vol. 10 (JCR21 IF: <span class="label label-danger">3.476</span>), 1 Oct. 2022, ISSN: 2169-3536, doi: https://doi.org/10.1109/ACCESS.2022.3203702</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ACCESS.2022.3203702" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>현대의 실시간 임베디드 시스템은 계산 집약적인 작업을 실행하기 위해 멀티코어 프로세서를 탑재하고 있다. 멀티코어 아키텍처에서는 마지막 단계의 캐시(last-level cache)가 여러 코어 간에 공유된다. 공유 캐시는 비결정적(non-deterministic) 자원이 되며, 이는 실시간 작업의 독립적인 실행에 영향을 미친다. 본 연구에서는 공유 캐시에서 간섭이 발생할 때 실행 시간의 변동을 완화하기 위한 해결책을 제안한다. 기존 방법들은 결정적인 실행 시간을 보장하기 위해 동시 메모리 접근을 회피하는 메모리 스케줄링 방식에 의존해 왔다. 그러나 이러한 방식은 최악 실행 시간(WCET)을 정확히 추정하기 위한 복잡한 분석이 필요하며, 결과적으로 지나치게 보수적인 방식으로 작업을 스케줄링해야 한다는 한계가 있다. 제안하는 방법은 기존 연구와 달리 복잡한 분석을 수행하지 않고, **메모리 배리어(memory barrier)의 부수 효과(side effect)**를 활용하여 동시 메모리 접근을 방지한다. 이를 위해 LLVM 컴파일러를 사용하여 기본 블록(basic block) 단위의 단순 코드 분석을 기반으로 메모리 배리어를 삽입한다. 제안된 방법은 운영체제나 작업 실행 흐름(task execution flow)을 수정할 필요가 없고, 분석 시간도 비교적 짧다. 방법의 유효성을 검증하기 위해, 멀티코어 환경에서 공유 캐시 간섭이 발생하는 상황을 가정하여 각 코어의 실행 시간 표준편차를 비교했다. 실험 결과, 제안하는 기본 블록 기반 메모리 배리어 삽입 방법은 간섭이 발생할 때 실행 시간의 변동을 최대 80%까지 감소시킬 수 있음을 확인하였다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#CD853F"><a href="">FGCS</a></abbr></div> <div id="lee2022quantune" class="col-sm-8"> <div class="title">Quantune: Post-training quantization of convolutional neural networks using extreme gradient boosting for fast deployment</div> <div class="author"> <em>Jemin Lee*</em>, <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, and <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a> </div> <div class="periodical"> <em>Future Generation Computer Systems Vol. 132, 2022, pp. 124-135, July 01, 2022 (JCR21 IF: <span class="label label-danger">7.307</span>, <span class="label label-warning">Top 9.09%</span>, computer science, theory &amp; method rank <span class="label label-warning">#10</span> out of 110), ISBN: 0167-739X, doi: https://doi.org/10.1016/j.future.2022.02.005</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/science/article/pii/S0167739X22000498?via%3Dihub" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/leejaymin/qaunt_xgboost" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>다양한 자원 제약 환경에서 합성곱 신경망(CNN)을 활용하기 위해서는, 정밀도 표현을 더 낮은 비트 표현으로 변환하는 양자화(quantization) 과정을 통해 CNN 모델을 압축하는 것이 필수적이다. 그러나 양자화 과정에서 발생하는 데이터셋 민감도 문제, 높은 계산 요구량, 많은 시간 소모 등을 해결하기 위해, 재학습을 필요로 하지 않는 사후 양자화(post-training quantization) 기법들이 제안되어 왔다. 또한, 재학습 없이 발생하는 정확도 저하를 보완하기 위해, 기존 사후 양자화 연구에서는 보정(calibration), 스킴(schemes), 클리핑(clipping), 세분화(granularity), 혼합 정밀도(mixed-precision) 등 다양한 보완 방법을 제안해 왔다. 최소한의 오류로 양자화된 모델을 생성하기 위해서는, 이러한 방법들이 상호 보완적이며 CNN 모델마다 특성이 다르기 때문에, 가능한 모든 조합을 탐색할 필요가 있다. 하지만 이를 전부 탐색하는 방식(exhaustive search)은 너무 많은 시간이 들고, 휴리스틱 기반 탐색은 최적 해(suboptimal)에 머물 가능성이 크다. 이러한 문제를 해결하기 위해, 우리는 Quantune이라는 자동 튜너(auto-tuner)를 제안한다. Quantune은 **그래디언트 트리 부스팅 모델(gradient tree boosting model)**을 구축하여 양자화 구성(configurations) 탐색을 가속화하고, 양자화 오류를 줄인다. Quantune은 랜덤 탐색, 그리드 탐색, 유전 알고리즘과 비교하여 평가되었다. 실험 결과, Quantune은 양자화 탐색 시간을 대폭 단축시키면서도, MobileNet, SqueezeNet, ShuffleNet과 같은 민감한 모델을 포함한 6개의 CNN 모델에서 0.07–0.65% 수준의 정확도 손실만을 보였다. 또한 Quantune은 다양한 타깃 장치를 지원하고 지속적으로 발전하는 양자화 연구를 수용하기 위해, 딥러닝용 통합 컴파일러 상에서 오픈소스로 구현되었다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MDPI</abbr></div> <div id="lee2022time" class="col-sm-8"> <div class="title">Time-Invariant Features-Based Online Learning for Long-Term Notification Management: A Longitudinal Study</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>Applied Sciences Vol. 12, No. 11 Article-Num. 5432, June 01, 2022 (JCR21 IF: <span class="label label-danger">2.838</span>) ISSN: 2076-3417, doi: https://doi.org/10.3390/app12115432</em>, Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>스마트폰과 웨어러블 기기에서 생성되는 일일 알림 수가 증가함에 따라 정신적 부담이 늘고, 생산성이 저하되며, 에너지가 낭비되는 문제가 나타나고 있다. 이러한 현상은 스마트폰, 스마트워치, 에어팟, 태블릿 등 사용자가 착용하거나 사용하는 개인 모바일 기기의 수가 증가함에 따라 더욱 심각해지고 있다. 여러 기기가 동시에 중복 알림을 생성할 수 있기 때문이다. 따라서 단순한 주의 분산뿐 아니라, 여러 기기가 유발하는 중복 알림은 에너지 낭비로 이어진다. 기존 연구에서는 PASS라는 알림 관리 시스템을 제안했으며, 이는 개인화된 모델을 기반으로 알림 발생을 자동으로 조절한다. 그러나 기존 연구에서는 시간 경과에 따른 사용자 행동 변화를 고려하지 않아, 머신러닝 기반 모델이 새로운 알림에 대해 제대로 작동하지 않는 문제가 있다. 모델이 장기간 사용될 때 발생하는 모델링과 실제 배치(deployment) 간의 성능 차이를 줄이기 위해, 우리는 장기간 데이터를 수집하는 **종단 연구(longitudinal study)**를 수행했다. 추가로 11,258개의 알림 데이터를 수집하여, 기존 데이터를 포함해 총 18,407개의 알림을 분석했으며, 전체 연구 기간은 2년에 걸친다. 통계적 검증을 통해 시간에 영향을 받지 않는(time-invariant) 특징을 식별했으며, 이를 모델 학습에 완전히 활용할 수 있음을 확인했다. 새롭게 발생하는 데이터로 인해 발생하는 정확도 하락 문제를 해결하기 위해, 우리는 시간 불변 윈도잉 온라인 학습(Windowing Time-Invariant Online Learning, WTOL) 기법을 설계했다. 새로 수집된 데이터셋에서 WTOL은 온라인 학습과 시간 민감도에 따른 윈도잉 특징을 결합하여, 기존 배치 학습 기반 모델의 F1-score를 44.3%에서 69.0%로 향상시켰다.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#1E90FF"><a href="">IEEE TMC</a></abbr></div> <div id="lee2019pass" class="col-sm-8"> <div class="title">PASS: Reducing redundant notifications between a smartphone and a smartwatch for energy saving</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://ic.kaist.ac.kr/members" rel="external nofollow noopener" target="_blank">Uichin Lee</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing,(impact factor: 5.538, JCR20: Top 17%, telecommunications rank #16 out of 91), ISSN: 1536-1233, doi: https://doi.org/10.1109/TMC.2019.2930506</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TMC.2019.2930506" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/leejaymin/nCollector" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MDPI</abbr></div> <div id="park2019hardware" class="col-sm-8"> <div class="title">Hardware resource analysis in distributed training with edge devices</div> <div class="author"> <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>Electronics Vol.9, Issue 1, pp.1-13, January 1, 2020 (JCR20 IF: <span class="label label-danger">2.397</span>), ISSN: 2079-9292, doi: https://doi.org/10.3390/electronics9010028</em>, Nov 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.mdpi.com/2079-9292/9/1/28" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC143C"><a href="">MobiCom</a></abbr></div> <div id="kang2019fire2" class="col-sm-8"> <div class="title">Fire in your hands: Understanding thermal behavior of smartphones</div> <div class="author"> <a href="https://scholar.google.com/citations?user=B9HMz0EAAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Soowon Kang</a>, Hyeonwoo Choi, Sooyoung Park, <a href="http://cjpark.xyz/" rel="external nofollow noopener" target="_blank">Chunjong Park</a>, <em>Jemin Lee</em>, <a href="https://ic.kaist.ac.kr/members" rel="external nofollow noopener" target="_blank">Uichin Lee</a>, and <a href="https://sites.google.com/site/wewantsj/" rel="external nofollow noopener" target="_blank">Sung-Ju Lee</a> </div> <div class="periodical"> <em>In The 25th Annual International Conference on Mobile Computing and Networking, pp. 1-16, Los Cabos, Mexico, 21-25 Oct. 2019, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19%</span> (55 papers accepted out of 290 submitted).</em>, Oct 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://dl.acm.org/citation.cfm?id=3300128" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://nmsl.kaist.ac.kr/projects/thermal/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">UbiComp</abbr></div> <div id="kang2018understanding" class="col-sm-8"> <div class="title">Understanding Customers’ Interests in the Wild</div> <div class="author"> <a href="https://scholar.google.com/citations?user=B9HMz0EAAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Soowon Kang</a>, Auk Kim, <em>Jemin Lee</em>, Ikhee Shin, and <a href="https://ic.kaist.ac.kr/members" rel="external nofollow noopener" target="_blank">Uichin Lee</a> </div> <div class="periodical"> <em>In Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers (Poster)</em>, Oct 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://dl.acm.org/citation.cfm?id=3267625" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/SuggestBot_Poster_final.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Hindawi</abbr></div> <div id="lee2018reducing" class="col-sm-8"> <div class="title">Reducing smartwatch users’ distraction with convolutional neural network</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a>, and  others</div> <div class="periodical"> <em>Mobile Information Systems, vol. 2018, Article ID 7689549, 9 pages, 15 Mar. 2018 (special issue in Advances in Personalized Mobile Services). (impact factor(JCR18): <span class="label label-danger">1.635</span>), ISSN: 1574-017X (print), 1875-905X(online)</em>, Oct 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.hindawi.com/journals/misy/aip/7689549/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#CD853F"><a href="">FGCS</a></abbr></div> <div id="joe2017output" class="col-sm-8"> <div class="title">Output-oriented power saving mode for mobile devices</div> <div class="author"> <a href="https://scholar.google.co.kr/citations?user=iHU86y8AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Hyunwoo Joe</a>, Jungseok Kim, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>Future Generation Computer Systems, 6 Jun. 2016, ISSN 0167-739X.<br>(impact factor: <span class="label label-danger">2.430</span>, JCR-2015: <span class="label label-warning">Top 10%</span>, theory &amp; methods category rank <span class="label label-warning">#11</span> out of 150)</em>, Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dx.doi.org/10.1016/j.future.2016.05.012" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">HENND</abbr></div> <div id="park2017emsoftco" class="col-sm-8"> <div class="title">Analysis of Hardware Resources in Distributed Learning (Poster)</div> <div class="author"> <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of International Workshop on Highly Efficient Neural Networks Design (co-located with EMSOFT), pp. 1-4, Seoul, South Korea, 20 Oct. 2017.</em>, Oct 2017 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IEEE IPIN</abbr></div> <div id="Jinse17s" class="col-sm-8"> <div class="title">An Ultrasound-based Indoor Localiztion Using Gaussian ASK Modulation (WIP)</div> <div class="author"> <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of International Conference on Indoor Positioning and Indoor Navigation, pp.1-4, Sapporo, Japan, 20 Sept. 2017.</em>, Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="http://www.ipin2017.org/ipinpapers/225/225.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IEMEK</abbr></div> <div id="park2017a" class="col-sm-8"> <div class="title">Deep Learning Training on Distributed Embedded Systems (Poster)</div> <div class="author"> <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of the 12th lEMEK Symposium on Embedded Technology, Busan, South Korea, 18-19 May, 2017.</em>, Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/iset2017.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/2017_ISET_park.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IoTDI</abbr></div> <div id="Jinyoung2017a" class="col-sm-8"> <div class="title">Extending App Pre-Launch Service with Emotion Context (Poster)</div> <div class="author"> Jinyoung Choi, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of the 2nd ACM/IEEE International Conference on Internet-of-Things Design and Implementation (IoTDI’17) Adjunct, pp. 1-2, Pittsburgh, USA, 18-21 Apr. 2017.</em>, Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dl.acm.org/citation.cfm?id=3057306" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/2017_IoTDI_choi_Poster.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Hindawi</abbr></div> <div id="lee2016qdroid" class="col-sm-8"> <div class="title">QDroid: Mobile application quality analyzer for app market curators</div> <div class="author"> <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>Mobile Information Systems, vol. 2016, Article ID 1740129, 11 pages, 10 Oct. 2016. (impact factor(JCR15): <span class="label label-danger">1.462</span>), ISSN: 1574-017X (print), 1875-905X(online)</em>, Oct 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dx.doi.org/10.1155/2016/1740129" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/leejaymin/QDroid" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MobileHCI</abbr></div> <div id="lee2016a" class="col-sm-8"> <div class="title">Reducing Distraction of Smartwatch Users with Deep Learning</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI’16) Adjunct pp. 948-953, Florence, Italy, 05-09 Sept. 2016.</em>, Oct 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dl.acm.org/citation.cfm?id=2962662" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/Smarttention_2016_Slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#1E90FF"><a href="">IEEE TCE</a></abbr></div> <div id="lee2014automated" class="col-sm-8"> <div class="title">Automated power model generation method for smartphones</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://scholar.google.co.kr/citations?user=iHU86y8AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Hyunwoo Joe</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>IEEE Transactions on Consumer Electronics</em>, Oct 2014 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dx.doi.org/10.1109/TCE.2014.6851993" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/PowerLab/PowerDoctor" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MobiSys</abbr></div> <div id="lee2013a" class="col-sm-8"> <div class="title">Framework for automated power estimation of Android applications (Poster)</div> <div class="author"> <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of the 11th annual international conference on Mobile Systems, Applications, and Services (<span class="label label-info">Mobisys’13</span>) Adjunct pp. 541-542, Taipei, Taiwan, Jun. 2013.</em>, Oct 2013 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dx.doi.org/10.1145/2462456.2465723" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="bibliography">2012</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">APSys</abbr></div> <div id="Vincent2012a" class="col-sm-8"> <div class="title">Energy Reservation Service for Smart Phone Application (Poster)</div> <div class="author"> Vincent Dupre, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of 3rd ACM/SIGOPS Asia-Pacific Workshop on Systems (APSys’12), Seoul, South Korea, Jul. 2012.</em>, Oct 2012 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICCE</abbr></div> <div id="lee2012a" class="col-sm-8"> <div class="title">Smart Phone Power Model Generation Using Use Pattern Analysis</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://scholar.google.co.kr/citations?user=iHU86y8AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Hyunwoo Joe</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of IEEE International Conference on Consumer Electronics (ICCE’12) pp. 412-413, Las Vegas, NV, USA, Jan. 2012.</em>, Oct 2012 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dx.doi.org/10.1109/ICCE.2012.6161925" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/ICCE2012.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2011</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">EKC</abbr></div> <div id="jemin2011" class="col-sm-8"> <div class="title">Smartphone, where does the power go?</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://scholar.google.co.kr/citations?user=iHU86y8AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Hyunwoo Joe</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>In In Proceedings of EU Korea Conference on Science and Technology (EKC’11), Paris, France, Jul. 2011.</em>, Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/EKC2011_smartphone_fullpaper.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> </div> <h2>ISSUED PATENTS</h2> <hr> <ol> <li><p><strong>Deep Learning Compiler with Support for Heterogeneous Computing Platforms and Its Method</strong><br> Korea Patent number 10-2777879, Granted 03/04/2025.<br> Misun Yu, Yongin Kwon, Taeho Kim, Jeman Park, <strong>Jemin Lee</strong></p></li> <li><p><strong>Method and system for expecting users' mood based on status information and biometric information acquired by using user equipment</strong><br> Korea Patent number 10-1749706, Granted 06/15/2017.<br> Hyungshin Kim, <strong>Jemin Lee</strong>, Jinyoung Choi</p></li> <li><p><strong>Method for Detecting Indoor Zone with Bluetooth and Ultrasound of Smartphone</strong><br> Korea Patent number 10-1742960, Granted 05/29/2017.<br> Hyungshin Kim, <strong>Jemin Lee</strong>, Jinse Kwon</p></li> <li><p><strong>System and Method for Detecting Beacon</strong><br> Korea Patent number 10-1741406, Granted 05/24/2017.<br> Hyungshin Kim, <strong>Jemin Lee</strong>, Seula Hwang</p></li> <li><p><strong>Portable terminal and method for controlling a battery charging of the same</strong><br> Korea Patent number 10-1650038, Granted 08/16/2016.<br> Hyungshin Kim, <strong>Jemin Lee</strong>, Donggeon Han</p></li> <li><p><strong>Search system and method of executable GUI.</strong><br> Korea Patent number 10-1513662, Granted 04/20/2015.<br> Hyungshin Kim, <strong>Jemin Lee</strong>, Donggeon Han</p></li> <li><p><strong>Collaborative Power Model Creation Method and Service Module With the Same.</strong><br> Korea Patent number 10-1266971, Granted 02/26/2013. <br> Hyungshin Kim, <strong>Jemin Lee</strong></p></li> </ol> <h2>Peer-reviewed Domestic Journals</h2> <hr> <ol> <li><p><a href="https://leejaymin.github.io/assets/pdf/dj2507.pdf">"대규모 언어 모델 가속을 위한 상용 가속기 기술 동향"</a>, <br> 박시형, <strong>이제민</strong>,김병수, 전석훈<br> 한국정보기술학회논문지 제23권 제6호 (JKIIT, Vol.23, No.6), 2025.06, 75 - 89 (15 pages), 학진등재지</p></li> <li><p><a href="https://koreascience.or.kr/article/JAKO202519236009219.page" rel="external nofollow noopener" target="_blank">"NPU 시스템 확장을 위한 데이터 전송 최적화"</a>, <br> 오세현, 권용인, <strong>이제민*</strong> <br> 대한임베디드공학회논문지 제 20권 제 3호 pp.125-130, 2025년 6월, 학진등재지</p></li> <li><p><a href="https://paper.cricit.kr/user/listview/ieie2018/gby_rdoc.asp?step=4&amp;organCode=ieie&amp;yearmonth=202401&amp;organCode2=ieie01&amp;usernum=0&amp;seid=&amp;dbcode=&amp;tbnm=r" rel="external nofollow noopener" target="_blank">"엣지 딥 러닝 가속기의 추론 성능 분석"</a>, <br> 박시형, 권용인, <strong>이제민*</strong> <br> 전자공학회논문지 Vol.61 No.1 pp.23-26, 2024.1, 우수둥재지</p></li> <li><p><a href="https://paper.cricit.kr/user/listview/ieie2018/doc_rdoc.asp?catvalue=3&amp;returnVal=RD_R&amp;organCode=ieie&amp;organCode2=ieie01&amp;yearmonth=202310&amp;page=1&amp;dn=424671&amp;step=&amp;usernum=0&amp;seid=" rel="external nofollow noopener" target="_blank">"범용 AI 컴파일러의 비공개 NPU 코드생성을 위한 공통 인터페이스 설계 및 검증"</a>, <br> <strong>이제민</strong>, 권용인*<br> 전자공학회논문지, v.60 no.10, pp.29-31, 2023.10.25, 우수등재지</p></li> <li><p><a href="https://paper.cricit.kr/user/listview/ieie2018/doc_rdoc.asp?catvalue=3&amp;returnVal=RD_R&amp;organCode=ieie&amp;organCode2=ieie01&amp;yearmonth=202307&amp;page=1&amp;dn=423544&amp;step=&amp;usernum=0&amp;seid=" rel="external nofollow noopener" target="_blank">"이기종 멀티코어 CPU에서 프로파일 기반 딥 러닝 연산 최적화 기법"</a>, <br> 차주형, 권용인*, <strong>이제민</strong> <br> 전자공학회논문지, v.60 no.7, pp.40-49, 2023.7.25, 우수등재지</p></li> <li><p><a href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11284518" rel="external nofollow noopener" target="_blank">"FPGA기반 뉴럴네트워크 가속기에서 2차 타일링 기반 행렬 곱셈 최적화"</a>, <br> 권진세, <strong>이제민</strong>, 권용인, 박제만, 유미선, 김태호, 김형신,<br> 대한임베디드공학회논문지 제17권 제6호 367-374, 2022.12, 학진등재지 </p></li> <li><p><a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE09304618" rel="external nofollow noopener" target="_blank">"인공지능 정보처리를 위한 뉴로모픽 HW기반 뉴로모픽 SW 플랫폼"</a>, <br> 김태호, 유미선, 김상철, 권용인, 김영주, 김용연, <strong>이제민</strong>, 마유승,<br> 정보과학회지 38(2) 40-50쪽 2020년 2월</p></li> <li><p><a href="http://ocean.kisti.re.kr/IS_mvpopo001P.do?method=multMain&amp;poid=ieek1&amp;kojic=OBDDBE&amp;free=" rel="external nofollow noopener" target="_blank">"스마트폰의 블루투스와 초음파를 이용한 향상된 실내 영역 결정"</a>, <br> 권진세, <strong>이제민</strong>, 김형신,<br> 대한임베디드공학회논문지 제11권 제3호 135-141쪽, 2016년 6월, ISSN 1975-5066, 학진등재지</p></li> <li><p><a href="http://www.dbpia.co.kr/Journal/ArticleDetail/NODE02505673" rel="external nofollow noopener" target="_blank">“GUI 버그 검출을 위한 블랙박스 기반의 시험”</a>,<br> <strong>이제민</strong>, 김형신,<br> 정보과학회논문지 제41권 제12호 1013-1017쪽, 2014년 12월, ISSN 2383-630X, 우수등재지</p></li> <li><p><a href="http://www.dbpia.co.kr/Journal/ArticleDetail/NODE02033308" rel="external nofollow noopener" target="_blank">“스마트폰 응용프로그램 에너지 소모 분석을 위한 프레임워크”</a>,<br> <strong>이제민</strong>, 조현우, 김형신,<br> 정보과학회논문지: 컴퓨팅의 실제 및 레터 제18권 제11호 780-784쪽, 2012년 11월, ISSN 1229-7712, 우수등재지 </p></li> </ol> <h2>Domestic Conference</h2> <hr> <ol> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc35.pdf">“라즈베리파이 5와 Hailo-8 및 8L의 AI 연산 성능 비교를 통한 엣지 디바이스 성능 향상 방안 연구”</a>, <br> 양병찬, 오세현, 차주형, <strong>이제민</strong>, 권용인,<br> 2025 정보처리학회 ASK 2025 학술발표대회 논문집, 2025.5.30 </p></li> <li><p><span class="label label-success">우수논문</span> <a href="https://leejaymin.github.io/assets/pdf/dc34.pdf">“PCIe 기반 다중 NPU 데이터 전송 최적화”</a>, <br> 오세현, 권용인, <strong>이제민*</strong>,<br> 2024 대한임베디드공학회 추계학술대회, 2024.11.14 </p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc33.pdf">“소형 언어 모델 가속기를 위한 기술 분석”</a>, <br> 박시형, <strong>이제민</strong>, 김병수, 전석훈<br> 2024 대한임베디드공학회 추계학술대회, 2023.11.15 </p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc32.pdf">“엣지 장치 기반 딥 러닝 분산 학습 성능 평가”</a>, <br> 박시형, <strong>이제민</strong>, 황태호,<br> 2023 대한임베디드공학회 추계학술대회, 2023.11.09 </p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc31.pdf">“The Harmony of Heterogeneous Computing Units in CNN Inference”</a>, <br> <strong>이제민</strong>,<br> 2022 전자공학회 하계학술대회, 2022.06 </p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc30.pdf">“Glow 컴파일러 확장을 통한 혼합정밀도 양자화”</a>, <br> <strong>이제민</strong>, 유미선, 권용인, 박제만, 김태호,<br> 2021 대한임베디드공학회추계학술대회, 2021.11.11 </p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc29.pdf">“이종 프로세싱 유닛 상에서의 분기 병렬 실행을 통한 뉴럴넷 계산 성능 향상”</a>, <br> 유미선, 권용인, <strong>이제민</strong>, 박제만, 김태호,<br> 2021 대한임베디드공학회추계학술대회, 2021.11.11 </p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc28.pdf">“확장 가능한 HLS 기반 딥러닝 가속 하드웨어 개발”</a>, <br> 권용인, 유미선, 박제만, <strong>이제민</strong>, 김태호,<br> 2021 대한임베디드공학회추계학술대회, 2021.11.11 </p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc27.pdf">“딥러닝 사진 분류기를 활용한 분리배출 가이드 안드로이드 응용”</a>, <br> 김소영, 박소희, 김민지, <strong>이제민</strong>, 김형신,<br> 2021 한국컴퓨터정보학회 하계학술대회 논문집 제29권 제2호, 2021.7</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc26.pdf">“NPU를 위한 연산자 퓨전 기반 양자화 신경망 모델의 정확도 향상”</a>, <br> <strong>이제민</strong>, 유미선, 권용인, 김영주, 김태호,<br> 2020 임베디드공학회 추계학술대회, 2020.11.12</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc25.pdf">“Glow 컴파일러 기반 타겟에 독립적인 연산자 퓨전을 활용한 CNN 추론 가속화”</a>, <br> <strong>이제민</strong>, 유미선, 권용인, 김영주, 김태호,<br> 2020 IEMEK Symposium on Embedded Technology (ISET 2020), 2020.7</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc24.pdf">“Glow 컴파일러를 활용한 CPU상에서의 물체 탐지 가속화 연구”</a>, <br> <strong>이제민</strong>, 권용인, 유미선, 김영주, 김태호,<br> 2020 한국컴퓨터종합학술대회, 2020.7</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc23.pdf">“다중 가속기 지원 딥러닝 컴파일러를 위한 프로파일링 기반 그래프 파티셔닝 시스템”</a>, <br> 유미선, 권용인, <strong>이제민</strong>, 김영주, 김태호,<br> 2020 IEMEK Symposium on Embedded Technology (ISET 2020), 2020.7</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc22.pdf">“HLS 기반 딥러닝 가속 하드웨어의 ISA 확장을 통한 성능 향상”</a>, <br> 권용인, 김영주, 유미선, <strong>이제민</strong>, 김태호,<br> 2020 IEMEK Symposium on Embedded Technology (ISET 2020), 2020.7</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc21.pdf">“임베디드 디바이스를 위한 딥뉴럴넷 C/C++ 코드 자동 생성 프레임워크”</a>, <br> 유미선, <strong>이제민</strong>, 권용인, 김영주, 김태호,<br> 2020 한국컴퓨터종합학술대회, 2020.7</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc20.pdf">“타일링과 스케줄링: 딥러닝 가속 하드웨어의 실행코드”</a>, <br> 권용인, 김영주, 유미선, <strong>이제민</strong>, 김태호,<br> 2020 한국컴퓨터종합학술대회, 2020.7</p></li> <li><p><span class="label label-success">우수논문</span><a href="https://leejaymin.github.io/assets/pdf/dc19.pdf">“모바일 IoT 서비스를 위한 데이터수집 프레임워크”</a>, <br> 유주원, 김수빈, 권유나, <strong>이제민</strong>, 최진영, 김형신,<br> 2019 한국소프트웨어종합학술대회, 2019.12.20.</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc18.pdf">“딥러닝 컴파일러 성능 비교”</a>, <br> 유미선, 김영주, <strong>이제민</strong>, 김태호,<br> 2019 한국컴퓨터종합학술대회, pp.1076-1078, 2019.6.26.</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc17.pdf">“YOLO-based Object Detection on ARM Mali GPU”</a>, <br> Trunghai Do, <strong>이제민</strong>, 김형신,<br> 2017 대한임베디드공학회 추계학술대회 논문집 27-30쪽, 2017년 11월 9일.</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/17ksci.pdf">“실내영역변화에 따른 저전력 비콘 탐지 기법”</a>, <br> 황슬아, 권진세, <strong>이제민</strong>, 김형신,<br> 2017 한국컴퓨터정보학회 하계학술대회 논문집 제25권 제2호 327-328쪽, 2017년 7월 14일.</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc15.pdf">“사물인터넷 기기에서의 프로그래밍 언어별 에너지 효율 비교”</a>, <br> 박시형, <strong>이제민</strong>, 김형신,<br> 2016 한국정보과학회 동계학술발표회 논문집 334-336쪽, 2016년 12월 21일.</p></li> <li><p><a href="https://leejaymin.github.io/assets/pdf/dc14.pdf">“초음파 변조와 블루투스 애드혹 네트워크를 이용한 재난 경보 시스템”</a>, <br> 권진세, <strong>이제민</strong>, 김형신,<br> 2016 대한임베디드공학회 추계학술대회 37-40쪽, 2016년 11월 11일. </p></li> <li><p><a href="http://www.dbpia.co.kr/Article/NODE06597364" rel="external nofollow noopener" target="_blank">“스마트폰 상황정보와 스마트시계의 심박 수를 이용한 감정 예측 모델”</a>, <br> 최진영, <strong>이제민</strong>, 김형신,<br> 2016 한국컴퓨터정보학회 동계학술대회 논문집 제24권 제1호 285-286쪽, 2016년 1월 15일.</p></li> <li><p><a href="https://drive.google.com/file/d/0B4pme20nXq8lblpQMkZLTU5xWVk/view?usp=sharing" rel="external nofollow noopener" target="_blank">“안드로이드의 배터리 이상 소모 검출 기법”</a>,<br> 방진성, 문민석, 라준혁, <strong>이제민</strong>, 김형신,<br> 2015 대한임베디드공학회 추계학술대회, 2015년 11월 14일.</p></li> <li><p><span class="label label-primary">우수발표</span> <a href="https://drive.google.com/file/d/0B4pme20nXq8lMVR2RzR4cjJXN0U/view?usp=sharing" rel="external nofollow noopener" target="_blank">“스마트폰 블루투스와 초음파를 이용한 실내 영역 결정 기법”</a>,<br> 권진세, <strong>이제민</strong>, 김형신,<br> 2015 대한임베디드공학회 추계학술대회, 2015년 11월 13일.</p></li> <li><p><span class="label label-success">우수논문</span> <a href="http://www.dbpia.co.kr/Article/NODE06597091" rel="external nofollow noopener" target="_blank">“Indoor Zone Detection based on Bluetooth Low Energy”</a>, <br> Jorge Frisancho, <strong>이제민</strong>, 김형신,<br> 2015 한국컴퓨터정보학회 하계학술대회 논문집 제23권 제2호 279-281쪽, 2015년 7월 10일.</p></li> <li><p><span class="label label-success">학부생 우수논문</span> <a href="http://www.dbpia.co.kr/Article/NODE06394553" rel="external nofollow noopener" target="_blank">“사용자 이동성을 고려한 저전력 비콘 탐지 기법”</a>, <br> 황슬아, <strong>이제민</strong>, 김형신,<br> 2015 한국정보과학회 한국컴퓨터종합학술대회 논문집 1790-1792쪽, 2015년 6월 25일.</p></li> <li><p><a href="http://www.dbpia.co.kr/Article/NODE06228617" rel="external nofollow noopener" target="_blank">“모바일 장치에서의 실제 배터리 용량 평가”</a>, <br> 한동건, <strong>이제민</strong>, 김형신,<br> 2014 한국정보과학회 제41회 정기총회 및 동계학술발표회 276-278쪽, 2014년 12월 18일.</p></li> <li><p><a href="http://www.dbpia.co.kr/Article/NODE06228643" rel="external nofollow noopener" target="_blank">“Smart Airplane Mode for Energy Saving on Smartphones”</a>, <br> Jorge Frisancho, <strong>이제민</strong>, 김형신,<br> 2014 한국정보과학회 제41회 정기총회 및 동계학술발표회 352-354쪽, 2014년 12월 19일.</p></li> <li><p><a href="http://www.dbpia.co.kr/Article/NODE06229084" rel="external nofollow noopener" target="_blank">“스마트폰을 이용한 협력형 실내 지형 측정 시스템”</a>, <br> 오현민, 최혜원, 김미정, <strong>이제민</strong>, 김형신,<br> 2014 한국정보과학회 제41회 정기총회 및 동계학술발표회 1625-1627쪽, 2014, 2014년 12월 19일.</p></li> <li><p><span class="label label-success">우수논문</span> <a href="http://www.dbpia.co.kr/Article/NODE02444025" rel="external nofollow noopener" target="_blank">“안드로이드 응용프로그램의 GUI Crash 버그 검출을 위한 자동화된 블랙박스 테스팅”</a>, <br> <strong>이제민</strong>, 김형신,<br> 2014 한국정보과학회 한국컴퓨터종합학술대회 논문집 359-361쪽, 2014년 6월 26일.</p></li> <li><p><a href="http://www.dbpia.co.kr/Article/NODE02323436" rel="external nofollow noopener" target="_blank">“안드로이드 마켓 응용프로그램들의 평점과 품질간의 연관성 분석”</a>, <br> <strong>이제민</strong>, 김형신,<br> 2013 한국정보과학회 제40회 정기총회 및 추계학술발표회 논문집 369-471쪽, 2013년 11월 16일.</p></li> <li><p><a href="http://www.dbpia.co.kr/Article/NODE02323432" rel="external nofollow noopener" target="_blank">“모바일 응용 프로그램들의 전력 소모 정보 제공 서비스”</a>, <br> 양태훈, 박용준, 이종욱, <strong>이제민</strong>, 김형신,<br> 2013 한국정보과학회 제40회 정기총회 및 추계학술발표회, 457-459쪽, 2013년 11월 16일.</p></li> <li><p><span class="label label-primary">우수발표</span> <a href="http://www.dbpia.co.kr/Article/NODE01907154" rel="external nofollow noopener" target="_blank">“스마트폰 응용프로그램 에너지 소모 분석을 위한 프레임워크”</a>, <br> <strong>이제민</strong>, 조현우, 김형신,<br> 2012 한국정보과학회 한국컴퓨터종합학술대회 논문집 제39권 제1호(D) 7-9쪽, 2012년 6월 29일.</p></li> <li><p><a href="http://www.dbpia.co.kr/Article/NODE01746070" rel="external nofollow noopener" target="_blank">“스마트폰 응용 프로그램의 소모전력 분석”</a>, <br> <strong>이제민</strong>, 조현우, 김형신,<br> 2011 한국정보과학회 추계학술발표논문집 제38권 제2호(D) 39-42쪽, 2011년 11월 25일.</p></li> </ol> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Jemin Lee. Last updated: January 08, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>