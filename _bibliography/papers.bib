---
---

string{aps = {American Physical Society,}}


The 26th ACM SIGPLAN/SIGBED International Conference on Languages,
Compilers, and Tools for Embedded Systems (LCTES 2025) program committee
is delighted to inform you that your submission #167 has been
*conditionally* accepted to appear in the conference.

@article{kim2025fgcs,
  abbr={FGCS},
  title={Towards an Efficient Dataflow-flexible Accelerator by Finding Optimal Dataflows of DNNs},
  author={Hyunjun Kim and Whoi Ree Ha and Yongseok Lee and Dongju Lee and Jongwon Lee and Deumji Woo and Jemin Lee and Yongin Kwon and Yunheung Paek},
  journal={Future Generation Computer Systems, 1 Mar 2026, 108123, ISSN: 0167-739X},
  month = {3},
  year={2026},
  pdf = {https://doi.org/10.1016/j.future.2025.108123}
}

@article{cha2025targetaware,
  abbr={IEEE TMC},
  title={Target-Aware Neural Network Execution via Compiler-Guided Pruning},
  author={JooHyoung Cha and Taeho Kim and Jemin Lee* and Sangtae Ha and Yongin Kwon*},
  journal={IEEE Transactions on Mobile Computing (to appear), Accepted Nov. 9, 2025},
  day = {9},
  month = {11},
  year={2025},
  selected={true},
  pdf = {https://ieeexplore.ieee.org/document/11240555}
}

@inproceedings{kim2026iptqvit,
  abbr={WACV},
  title={IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers},
  author={Gihwan Kim and Jemin Lee and Hyungshin Kim},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026, Round 1 acceptance rate <span class="label label-warning">6.4%</span>, Round 2 acceptance rate <span class="label label-warning">41.1%</span>, Overall acceptance rate <span class="label label-warning">26.4%</span>},
  month = {2},
  year={2026}
}

@inproceedings{caseswip2025,
    abbr={CASES},
    title={I-FlashAttention: Fully Integer Fused Attention for Efficient Vision Transformers (WIP)},
    author={Sehyeon Oh and Yongin Kwon and Jemin Lee*},
    booktitle={ACM International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (ESWEEK CASES 2025), Acceptance Rate 57.1% (4 papers accepted out of 7 invited) September 30, 2025.},
    month = {9},
    year={2025},
    organization={IEEE},
    pdf = {wip_i_flash.pdf}
}


@inproceedings{cases25,
  abbr={CASES},
  award = {Artifacts},
  title={Luthier: Bridging Auto-Tuning and Vendor Libraries for Efficient Deep Learning Inference},
  author={Yongin Kwon and JooHyoung Cha and Sehyeon Oh and Misun Yu and Jeman Park and Jemin Lee*},
  booktitle = {ACM International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (ESWEEK CASES 2025)
  (NRF BK21+ IF: 2, Acceptance Rate 28.2% (20 papers accepted out of 71 submitted)) and
  ACM Transactions on Embedded Computing Systems (TECS) Vol. 24, No. 5s, pp. 1--23 ISSN:1539-9087, September 29, 2025.},
  pages={1--20},
  month = {9},
  year={2025},
  selected={true},
  pdf = {https://dl.acm.org/doi/10.1145/3759916},
  poster = {luthier_poster.pdf},
  slides = {luthier_slides.pdf},
  code = {https://gitlab.com/ones-ai/Luthier},
  doi = {10.1145/3759916},
  abstract = {최근 딥러닝 컴파일러는 텐서 프로그래밍에서 최적의 커널 구성을 처음부터 탐색하는 자동 튜닝 방식을 주로 채택하는데, 이는 작업당 수십 시간이 소요되며 비대칭 멀티코어 프로세서에서의 병렬 컴퓨팅에 필수적인 최적화 요소를 간과합니다. 한편 하드웨어 벤더의 수동 최적화 추론 라이브러리는 높은 성능을 제공하지만 신흥 모델에 필요한 유연성과 자동화가 부족합니다. 이러한 격차를 해소하기 위해 우리는 기존 추론 라이브러리에서 최적의 커널을 선별하여 탐색 공간을 크게 축소하고, 비용 모델 기반 프로파일링을 활용해 병렬 컴퓨팅에 가장 효율적인 작업 부하 분배를 신속히 결정하는 Luthier를 제안합니다. 그 결과 Luthier는 ArmNN, AutoTVM, Ansor, ONNXRuntime, TFLite 대비 평균 튜닝 시간을 95% 단축하면서, CPU와 GPU 모두에서 컨볼루션 기반 비전 모델과 트랜스포머 기반 언어 모델(BERT, GPT)에서 최대 2.0배 빠른 실행 속도를 달성합니다.
}
}

@inproceedings{acvr25_1,
  abbr={ICCV W.},
  title={Design Practices and Lessons from Deploying On-device Vision-Language Interaction in Robotic Guide Dogs},
  author={Jinse Kwon and Jemin Lee* and Yongin Kwon*},
  booktitle = {ICCV Workshop ACVR 2025},
  pages={1--10},
  month = {7},
  year={2025},
  pdf = {https://openaccess.thecvf.com/content/ICCV2025W/ACVR/papers/Kwon_Design_Practices_and_Lessons_from_Deploying_On-device_Vision-Language_Interaction_in_ICCVW_2025_paper.pdf},
  code = {}
}

@inproceedings{acvr25_2,
  abbr={ICCV W.},
  title={TriPlanNet: Triangle Path Planning Network for A Variable Truss Robot with Deep Learning},
  author={Choonghan Lee and Leah Harris and Sehyeon Oh and Juhyung Cha and Jemin Lee and Yongin Kwon and Andrew Jang-ho Bae},
  booktitle = {ICCV Workshop ACVR 2025},
  pages={1--10},
  month = {7},
  year={2025},
  pdf = {https://openaccess.thecvf.com/content/ICCV2025W/ACVR/papers/Lee_TriPlanNet_Triangle_Path_Planning_Network_for_A_Variable_Truss_Robot_ICCVW_2025_paper.pdf},
  code = {}
}

@inproceedings{lee25survey,
  abbr={Preprint},
  title={A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency},
  author = {Sihyeong Park and Sungryeol Jeon and Chaelyn Lee and Seokhun Jeon and Byung-Soo Kim and Jemin Lee*},
  booktitle = {Preprint on ArXiv 2505.01658 May 3, 2025},
  pages={1--65},
  month = {5},
  year={2025},
  pdf = {https://arxiv.org/abs/2505.01658},
  code = {https://github.com/sihyeong/Awesome-LLM-Inference-Engine}
}

@inproceedings{lee25ijcai,
  abbr={IJCAI},
  title={Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant},
  author={Jemin Lee and Sihyeong Park and Jinse Kwon and Jihun Oh and Yongin Kwon*},
  booktitle={International Joint Conferences on Artificial Intelligence (IJCAI) Aug. 22, 2025, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19.3%</span> (1042 papers accepted out of 5404 submitted).},
  pages={8113--8121},
  month = {8},
  year={2025},
  selected={true},
  pdf = {https://doi.org/10.24963/ijcai.2025/902},
  code = {https://gitlab.com/ones-ai/eval-quant-llms},
  abstract = {양자화는 대규모 및 소규모 언어 모델의 비용 효율적 배포를 위한 유망한 해결책으로 주목받고 있습니다. 그러나 기존 연구 대부분은 퍼플렉시티나 기초 지식 작업에 국한되어 있으며 Llama-3.3과 같은 최신 모델에 대한 포괄적 평가가 부족했습니다. 본 논문에서는 10억에서 4050억 매개변수에 이르는 명령어 학습 모델을 대상으로 13개 데이터셋에 걸쳐 4가지 양자화 기법을 적용하여 포괄적 평가를 수행합니다.
우리의 연구 결과는 다음과 같다: (1) 양자화 모델은 일반적으로 더 작은 FP16 기준 모델을 능가하지만, 명령어 수행 및 환각 탐지에서는 종종 어려움을 겪는다; (2) FP8은 모든 작업에서 가장 견고한 옵션으로 꾸준히 나타났으며, 가중치 전용 양자화에서는 AWQ가 GPTQ보다 우수한 성능을 보이는 경향이 있다; (3) 소규모 모델은 4비트 양자화 시 심각한 정확도 하락을 겪을 수 있는 반면, 70B 규모 모델은 안정적인 성능을 유지한다; (4) 특히, 어려운 작업이 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 모델의 본질적 약점을 증폭시키기보다는 가려진 부분을 드러낸다는 점을 시사한다.
4비트 양자화 시 심각한 정확도 하락을 보일 수 있으나, 70B 규모 모델은 안정적인 성능을 유지함; (4) 특히 어려운 과제가 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 단순히 과제 난이도와 상관관계를 가지는 것이 아니라 모델의 내재적 약점을 증폭시킨다는 점을 시사함; (5) LLM 기반 평가 도구(MTBench)는 코딩 및 STEM 과제에서 상당한 성능 저하를 강조하지만, 추론에서는 가끔 개선을 보고함.}
}
%  16-12 Aug. 2025

@inproceedings{lectes25,
  abbr={LCTES},
  title={Multi-Level Machine Learning-Guided Autotuning for Efficient Code Generation on a Deep Learning Accelerator},
  author={JooHyoung Cha and Munyoung Lee and Jinse Kwon and Jemin Lee and Yongin Kwon},
  booktitle={The 26th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)
  Jun. 17, 2025, To appear, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">38%</span> (16 papers accepted out of 42 submitted).},
  pages={134--145},
  month = {6},
  year={2025},
  selected={true},
  pdf = {https://doi.org/10.1145/3735452.3735538},
  abstract = {딥 러닝 모델의 복잡성 증가는 특히 딥 러닝 가속기를 위한 특수 하드웨어 및 소프트웨어 최적화를 필요로 합니다. 기계 학습 기반 자동 튜닝 방법이 수동 작업을 줄이는 유망한 해결책으로 부상했지만, 템플릿 기반 및 템플릿 프리 접근법 모두 유효하지 않은 구성 프로파일링으로 인해 튜닝 시간이 길어지는 문제점을 안고 있으며, 이는 런타임 오류로 이어질 수 있습니다. 이 문제를 해결하기 위해 효율성과 견고성을 개선하도록 설계된 다단계 머신 러닝 기반 자동 튜닝 기술인 ML2Tuner를 제안합니다. ML2Tuner는 두 가지 핵심 아이디어를 도입합니다: (1) 프로파일링 전에 무효한 구성을 걸러내는 유효성 예측 모델, (2) 컴파일 과정에서 추출된 숨겨진 특징을 활용하는 고급 성능 예측 모델입니다. 확장된 VTA 가속기에서의 실험 결과, ML2Tuner는 TVM 유사 접근법이 요구하는 샘플의 12.3%만을 사용하여 동등한 성능 향상을 달성하며, 무효 프로파일링 시도를 평균 60.8% 감소시킵니다. 이는 무효 구성을 걸러내어 자동 튜닝 성능을 향상시킬 수 있는 잠재력을 보여줍니다.}
}
%  16-17 Jun. 2025

@inproceedings{QuantuneV2,
  abbr={FGCS},
  title={QuantuneV2: Compiler-based local metric-driven mixed precision quantization for practical embedded AI applications},
  author={Jeongseok Kim** and Jemin Lee** and Yongin Kwon and Daeyoung Kim},
  booktitle={Future Generation Computer Systems Volume 166, May 1, 2025, 107718 (JCR24 IF: 6.1, Top 9.86%, Q1), ISSN: 0167-739X},
  pages={1--18},
  day = {1},
  month = {5},
  year={2025},
  pdf = {https://doi.org/10.1016/j.future.2025.107718},
  abstract = {혼합 정밀도 양자화 기법은 정확도 저하를 최소화하면서 모델 크기를 줄이기 위해 제안되어 왔다. 그러나 기존 연구들은 재학습이 필요하며, 컴파일 과정에서 발생하는 계산 오버헤드와 중간 표현(IR)을 고려하지 않아 컴파일러 수준에서의 적용에 한계가 있다. 여기서 말하는 계산 오버헤드는 추론 과정에서 빈번하게 수행되는 양자화 및 비양자화 연산으로 인해 발생하는 런타임 지연을 의미한다. 이러한 연산을 개별 연산자 단위로 수행할 경우 런타임이 크게 증가한다.
  이 문제를 해결하기 위해, 우리는 실질적인 임베디드 AI 응용을 위해 설계된 컴파일러 기반 혼합 정밀도 양자화 방법인 QuantuneV2를 제안한다. QuantuneV2는 양자화 전과 양자화 후 단 두 번만 추론을 수행하며, 모델 파라미터 수에 비례해 선형적으로 증가하는 계산 복잡도를 가진다. 또한 가중치, 활성값, 신호대양자화잡음비(SQNR), 평균제곱오차(MSE)와 같은 로컬 메트릭을 활용하여 민감도 분석을 더욱 안정적으로 만들었다. 아울러 최적의 IR을 선택하고 연산자 융합(operator fusion)을 적용하여 계산 오버헤드를 줄였다.
  실험 결과, QuantuneV2는 ResNet18v1, ResNet50v1, SqueezeNetv1, VGGNet, MobileNetv2 등 다섯 가지 모델에서 기존 방법 대비 최대 10.28%의 정확도 향상과 12.52%의 속도 향상을 달성했다. 이는 QuantuneV2가 계산 효율성을 유지하면서 모델 성능을 향상시켜 임베디드 AI 환경에 적합함을 보여준다.}
}

@inproceedings{sensors25,
  abbr={Sensors},
  award = {Invited},
  title={Optimizing Real-Time Object Detection in a Multi NPU Systems},
  author={Sehyeon Oh and Yongin Kwon  and Jemin Lee*},
  booktitle={MDPI Sensors, Volume 25, Issue 5, pp. 1376 March 1 2025 EISSN 1424-8220 (JCR23 IF: 3.4, JCR23 Top 30.9%, Q2)},
  pages={1--13},
  day = {1},
  month = {3},
  year={2025},
  pdf = {https://doi.org/10.3390/s25051376},
}


@inproceedings{AIcompS24oh,
  abbr={AIcompS},
  award = {Distinguished},
  title={Optimizing Real-Time Object Detection in a Multi NPU System with Double Buffering and Queue-Based Processing},
  author={Sehyeon Oh and Yongin Kwon  and Jemin Lee*},
  booktitle={The 1st International Conference on Artificial Intelligence Computing and Systems},
  pages={1--4},
  day = {16},
  month = {12},
  year={2024},
  pdf = {https://leejaymin.github.io/assets/pdf/aicomps_oh.pdf},
}

@inproceedings{AIcompS24park,
  abbr={AIcompS},
  title={A Review on Proprietary Accelerators for Large Language Models},
  author={Sihyeong Park and Jemin Lee and Byung-Soo Kim and Seokhun Jeon},
  booktitle={The 1st International Conference on Artificial Intelligence Computing and Systems},
  pages={1--4},
  day = {16},
  month = {12},
  year={2024},
  pdf = {https://aicomps.kips.or.kr/},
}

@inproceedings{ml2tuner,
  abbr={NeurIPS W.},
  title={ML^2Tuner: Efficient Code Tuning via Multi-Level Machine Learning Models},
  author={JooHyoung Cha and Munyoung Lee and Jinse Kwon and Jubin Lee and Jemin Lee and Yongin Kwon},
  booktitle={Machine Learning for Systems Workshop at NeurIPS},
  pages={1--12},
  month = {12},
  year={2024},
  pdf = {https://mlforsystems.org/assets/papers/neurips2024/paper6.pdf},
}

@article{jemin2024Qhyvit,
    abbr={IEEE IoT J.},
    title={Q-HyViT: Post-Training Quantization for Hybrid Vision Transformer with Bridge Block Reconstruction for IoT Systems},
    author={Jemin Lee and Yongin Kwon and Misun Yu and Jeman Park and Hwanjun Song},
    journal={IEEE Internet of Things Journal Vol. 11, Issue 22, pp.36384-36396, ISSN: 2327-4662, Nov. 15, 2025 (JCR24 IF: 8.9 Top 4.07%)},
    publisher={IEEE},
    pages={36384--36396},
    day = {15},
    month = {11},
    year={2024},
    selected={false},
    pdf={https://doi.org/10.1109/JIOT.2024.3403844},
    code = {https://gitlab.com/ones-ai/q-hyvit},
    abstract = {최근 비전 트랜스포머(ViT)는 분류, 탐지, 세분화 등 다양한 응용 분야에서 합성곱 신경망(CNN)을 대체하며 뛰어난 성능을 보이고 있다. 그러나 ViT의 높은 계산 요구량은 광범위한 활용을 어렵게 만든다. 이러한 문제를 해결하기 위해 연구자들은 합성곱 레이어와 트랜스포머 레이어를 결합하고, 선형 복잡도의 최적화된 어텐션 계산을 사용하는 효율적인 하이브리드 트랜스포머 아키텍처를 제안해 왔다. 또한 사후학습 양자화(PTQ)가 계산 부담을 줄이는 방법으로 제시되었다. 모바일 장치에서 ViT의 최적 가속을 달성하려면 양자화 기법과 효율적인 하이브리드 트랜스포머 구조를 전략적으로 통합해야 한다. 그러나 지금까지 효율적인 하이브리드 트랜스포머에 양자화를 적용한 연구는 없었다.
    이 논문에서는 기존의 ViT용 PTQ 기법을 효율적인 하이브리드 트랜스포머에 적용할 경우 정확도가 크게 떨어진다는 사실을 발견했으며, 이는 매우 동적인 값 범위, 제로포인트 오버플로, 다양한 정규화 방식, 5M 미만의 제한된 모델 파라미터 수 등 네 가지 문제 때문이라고 밝힌다. 이러한 문제를 해결하기 위해 우리는 새로운 PTQ 기법을 제안하며, 이는 MobileViTv1, MobileViTv2, Mobile-Former, EfficientFormerV1, EfficientFormerV2 등 효율적인 하이브리드 ViT를 최초로 양자화한 방법이다.
    우리 방법은 기존 PTQ 기법(EasyQuant, FQ-ViT, PTQ4ViT, RepQ-ViT) 대비 8비트에서 평균 17.73%, 6비트에서 평균 29.75%의 성능 향상을 달성했다. 코드는 https://gitlab.com/ones-ai/q-hyvit 에서 공개할 예정이다.}
}

@inproceedings{park2024etri,
  abbr={ETRI J.},
  title={NEST-C: A Deep Learning Compiler Framework for Heterogeneous Computing Systems with AI Accelerators},
  author={Jeman Park and Misun Yu and Jinse Kwon and Junmo Park and Jemin Lee* and Yongin Kwon*},
  booktitle={ETRI Journal Vol. 46 Issue 5, pp.851-864 ISSN: 1225-6463 (JCR24 IF 1.6, 70%) Oct. 28, 2024},
  pages={851--864},
  day = {28},
  month = {10},
  year={2024},
  pdf = {https://doi.org/10.4218/etrij.2024-0139},
  code = {https://gitlab.com/ones-ai/nest-compiler},
  abstract = {딥 러닝(DL)은 인공 지능(AI)을 크게 발전시켰으나, PyTorch, ONNX, TensorFlow와 같은 프레임워크는 범용 GPU에 최적화되어 있어 신경 처리 장치(NPU) 및 메모리 내 처리(PIM) 장치와 같은 특수 가속기에서 비효율적입니다. 이러한 가속기는 처리량과 에너지 효율을 모두 최적화하도록 설계되었지만, 보다 맞춤화된 최적화가 필요합니다. 이러한 한계를 해결하기 위해 우리는 다양한 AI 가속기에서 모델 배포 및 성능을 개선하는 새로운 DL 프레임워크인 NEST 컴파일러(NEST-C)를 제안합니다. NEST-C는 프로파일링 기반 양자화, 동적 그래프 분할, 다단계 중간 표현(IR) 통합을 활용하여 다양한 하드웨어 플랫폼에서 효율적인 실행을 가능하게 합니다. 연구 결과 NEST-C는 다양한 AI 가속기에서 계산 효율성과 적응성을 크게 향상시켜 더 높은 처리량, 낮은 지연 시간, 개선된 자원 활용도, 향상된 모델 이식성을 달성합니다. 이러한 이점은 현대 AI 애플리케이션에서 더 효율적인 DL 모델 배포에 기여합니다.}
}

@inproceedings{gihwan2024Eccv,
  abbr={ECCV W.},
  title={Mixed Non-linear Quantization for Vision Transformers},
  author={Gihwan Kim** and Jemin Lee** and Sihyeong Park and Yongin Kwon and Hyungshin Kim},
  booktitle={ECCV Workshop CADL},
  pages={1--17},
  month = {9},
  year={2024},
  pdf = {https://arxiv.org/abs/2407.18437},
  code = {https://gitlab.com/ones-ai/mixed-non-linear-quantization}
}

@inproceedings{VisualIROS2024,
  abbr={IROS},
  title={Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation},
  author={Joonhyung Lee and Sangbeom Park and Yongin Kwon and Jemin Lee and Minwook Ahn and Sungjoon Choi},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)},
  pages={1--8},
  month = {6},
  year={2024},
  selected={true},
  pdf = {https://arxiv.org/abs/2403.11513},
  code = {https://github.com/joonhyung-lee/vpi},
  website = {https://joonhyung-lee.github.io/vpi/}
}


@article{kwon2023pipelining,
  abbr={IEEE ESL},
  title={Pipelining of a Mobile SoC and an External NPU for Accelerating CNN Inference},
  author={Kwon, Jinse and Lee, Jemin and Kim, Hyungshin},
  journal={IEEE Embedded Systems Letters, Vol. 16 Issue 2 pp. 150-153, June 2024 ISSN 1943-0663 (JCR24 IF 2, 55.08), doi: https://doi.org/10.1109/LES.2023.3305016},
  month = {6},
  year={2024},
  publisher={IEEE},
  pdf={https://doi.org/10.1109/LES.2023.3305016},
    abstract = {하드웨어와 소프트웨어의 공동 발전에 따라 컨볼루션 신경망(CNN) 알고리즘이 에지 디바이스에 점점 더 많이 배포되고 있습니다. 리소스가 제한된 디바이스에 CNN을 배포하려면 종종 CPU와 GPU의 최적화가 필요합니다. 신경망 처리 장치(NPU)와 같은 전용 하드웨어가 성공적으로 도입되었지만, CPU, GPU 및 NPU 간의 협력적 방법은 아직 미성숙한 상태입니다. 본 논문에서는 모바일 시스템온칩(SoC)과 외부 NPU(eNPU)의 통합을 최적화하여 조화로운 파이프라이닝을 달성하고 추론 속도 및 처리량을 향상시키기 위한 두 가지 접근법을 제안한다. 첫 번째 접근법은 호스트 측에서 레이어별 최적 라이브러리를 할당하기 위한 기본 선형 대수 서브프로그램 라이브러리 검색 방식을 포함하며, 두 번째 접근법은 모델 슬라이스 포인트를 탐색하여 성능을 최적화한다. 자동 할당되는 계산 라이브러리로 CPU 기반 NNPACK, OpenBLAS 및 GPU 기반 CLBlast를 활용합니다. 전체 신경망(NN)은 NN 레이어 특성과 하드웨어 성능을 기반으로 두 부분으로 최적 분할됩니다. Hikey-970, Hikey-960, Firefly-rk3399 등 다양한 모바일 기기에서 알고리즘을 평가했습니다. 실험을 통해 제안된 파이프라인 추론 방식이 eNPU 및 SoC에서의 병렬 실행 대비 지연 시간을 10% 감소시키고 처리량을 17% 이상 증가시킨다는 점을 입증했습니다.}
}

@inproceedings{VisualICRAW,
  abbr={ICRA W.},
  title={Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation},
  author={Joonhyung Lee and Sangbeom Park and Yongin Kwon and Jemin Lee and Minwook Ahn and Sungjoon Choi},
  booktitle={First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024},
  pages={1--6},
  year={2024},
  pdf = {https://openreview.net/forum?id=D2e4URvhpP},
}

@inproceedings{acltuner,
  abbr={NeurIPS W.},
  title={ACLTuner: A Profiling-Driven Fast Tuning to Optimize Deep Learning Inference},
  author={Yongin Kwon and Joo Hyoung Cha and Jubin Lee and Misun Yu and Jeman Park and Jemin Lee*},
  booktitle={Machine Learning for Systems Workshop at NeurIPS},
  pages={1--4},
  year={2023},
  pdf = {https://openreview.net/pdf?id=k0FIPHpeR4},
}

@article{yu2023partitiontuner,
    abbr={ETRI J.},
    title={PartitionTuner: An operator scheduler for deep-learning compilers supporting multiple heterogeneous processing units},
    author={Yu, Misun and Kwon, Yongin and Lee, Jemin and Park, Jeman and Park, Junmo and Kim, Taeho},
    journal={ETRI Journal Vol. 45 No. 2, Apr. 20, 2023 (JCR23 IF: 1.3) ISSN: 1225-6463, doi: https://doi.org/10.4218/etrij.2021-0446},
    volume={45},
    number={2},
    pages={318--328},
    day = {20},
    month = {4},
    year={2023},
    publisher={Wiley Online Library},
    selected={false},
    pdf={https://doi.org/10.4218/etrij.2021-0446},
    abstract = {최근 모바일 플랫폼과 같은 임베디드 시스템은 중앙 처리 장치(CPU)와 신경망 처리 장치(NPU) 등 병렬로 작동할 수 있는 다중 처리 장치를 갖추고 있습니다. 딥 러닝 컴파일러를 활용하면 딥 신경망(DNN)으로부터 이러한 임베디드 시스템에 최적화된 기계 코드를 생성할 수 있습니다. 그러나 지금까지 제안된 딥러닝 컴파일러는 단일 처리 장치에서 DNN 연산자를 순차적으로 실행하는 코드나 그래픽 처리 장치(GPU)용 병렬 코드만을 생성합니다. 본 연구에서는 CPU와 NPU를 포함한 다중 이종 처리 장치(PU)를 지원하는 딥러닝 컴파일러용 연산자 스케줄러인 PartitionTuner를 제안합니다. PartitionTuner는 전체 DNN 추론 시간을 최소화하기 위해 사용 가능한 모든 PU를 동시에 활용하는 연산자 스케줄링 계획을 생성할 수 있습니다. 연산자 스케줄링은 DNN 아키텍처 분석과 이종 처리 장치에서 측정된 개별 및 그룹 연산자의 성능 프로파일을 기반으로 합니다. 7개 DNN에 대한 실험 결과, PartitionTuner는 SqueezeNet에 대해 정적 타입 기반 연산자 스케줄링 기법보다 5.03% 더 우수한 성능을 보이는 스케줄링 계획을 생성합니다. 또한 PartitionTuner는 ResNet50, ResNet18, SqueezeNet에 대해 각각 7.18%, 5.36%, 2.73%로 최근 프로파일링 기반 연산자 스케줄링 기법보다 우수한 성능을 보입니다.}
}

% within 3 years

@inproceedings{kim2022cprune,
    abbr={ECCV},
    title={CPrune: Compiler-informed model pruning for efficient target-aware DNN execution},
    author={Kim, T. and Kwon, Yongin and Lee, Jemin and Kim, Taeho and Ha, Sangtae},
    booktitle={European Conference on Computer Vision (ECCV), pp.651–667, Oct. 23-27, 2022, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">28%</span> (1,650 papers accepted out of 5,803 submitted),
  doi: https://doi.org/10.1007/978-3-031-20044-1_37},
    pages={651--667},
    month = {10},
    year={2022},
    organization={Springer},
    selected={true},
    pdf = {https://doi.org/10.1007/978-3-031-20044-1_37},
    code = {https://github.com/taehokim20/CPrune}
}

@article{park2022software,
    abbr={Access},
    title={Software-Level Memory Regulation to Reduce Execution Time Variation on Multicore Real-Time Systems},
    author={Park, Sihyeong and Lee, Jemin and Kim, Hyungshin},
    journal={IEEE Access Vol. 10 (JCR21 IF: <span class="label label-danger">3.476</span>), 1 Oct. 2022, ISSN: 2169-3536, doi: https://doi.org/10.1109/ACCESS.2022.3203702},
    volume={10},
    pages={93799--93811},
    year={2022},
    publisher={IEEE},
    pdf = {https://doi.org/10.1109/ACCESS.2022.3203702}
}

@article{lee2022quantune,
  abbr={FGCS},
  title={Quantune: Post-training quantization of convolutional neural networks using extreme gradient boosting for fast deployment},
  author={Jemin Lee* and Yu, Misun and Kwon, Yongin and Kim, Taeho},
  journal={Future Generation Computer Systems Vol. 132, 2022, pp. 124-135, July 01, 2022 (JCR21 IF:
          <span class="label label-danger">7.307</span>, <span class="label label-warning">Top 9.09%</span>,
          computer science, theory & method rank <span class="label label-warning">#10</span> out of 110), ISBN: 0167-739X,
          doi: https://doi.org/10.1016/j.future.2022.02.005},
  volume={132},
  pages={124--135},
  day = {1},
  month = {7},
  year={2022},
  publisher={Elsevier},
  pdf = {https://www.sciencedirect.com/science/article/pii/S0167739X22000498?via%3Dihub},
  code = {https://github.com/etri/nest-compiler},
  code = {https://github.com/leejaymin/qaunt_xgboost},
}

@article{lee2022time,
  abbr={MDPI},
  title={Time-Invariant Features-Based Online Learning for Long-Term Notification Management: A Longitudinal Study},
  author={Lee, Jemin and Park, Sihyeong and Kim, Taeho and Kim, Hyungshin},
  journal={Applied Sciences Vol. 12, No. 11 Article-Num. 5432, June 01, 2022 (JCR21 IF: <span class="label label-danger">2.838</span>) ISSN: 2076-3417, doi: https://doi.org/10.3390/app12115432},
  volume={12},
  number={11},
  pages={5432},
  month = {6},
  year={2022},
  publisher={MDPI}
}

@article{lee2019pass,
    abbr={IEEE TMC},
    title={PASS: Reducing redundant notifications between a smartphone and a smartwatch for energy saving},
    author={Lee, Jemin and Lee, Uichin and Kim, Hyungshin},
    journal={IEEE Transactions on Mobile Computing,(impact factor: 5.538, JCR20: Top 17%, telecommunications rank #16 out of 91), ISSN: 1536-1233, doi: https://doi.org/10.1109/TMC.2019.2930506},
    volume={19},
    number={11},
    pages={2656--2669},
    month = {11},
    year={2020},
    publisher={IEEE},
    selected={true},
    pdf={https://doi.org/10.1109/TMC.2019.2930506},
    code = {https://github.com/leejaymin/nCollector}
}

@article{park2019hardware,
  abbr={MDPI},
  title={Hardware resource analysis in distributed training with edge devices},
  author={Park, Sihyeong and Lee, Jemin and Kim, Hyungshin},
  journal={Electronics Vol.9, Issue 1, pp.1-13, January 1, 2020 (JCR20 IF: <span class="label label-danger">2.397</span>), ISSN: 2079-9292,
        doi: https://doi.org/10.3390/electronics9010028},
  volume={9},
  number={1},
  pages={28},
  year={2019},
  publisher={MDPI},
  pdf = {https://www.mdpi.com/2079-9292/9/1/28}
}

@inproceedings{kang2019fire2,
    abbr={MobiCom},
    title={Fire in your hands: Understanding thermal behavior of smartphones},
    author={Kang, Soowon and Choi, Hyeonwoo and Park, Sooyoung and Park, Chunjong and Lee, Jemin and Lee, Uichin and Lee, Sung-Ju},
    booktitle={The 25th Annual International Conference on Mobile Computing and Networking, pp. 1-16, Los Cabos, Mexico, 21-25 Oct. 2019, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19%</span> (55 papers accepted out of 290 submitted).},
    pages={1--16},
    month = {10},
    year={2019},
    selected={true},
    pdf = {https://dl.acm.org/citation.cfm?id=3300128},
    website = {https://nmsl.kaist.ac.kr/projects/thermal/},
    video = {https://youtu.be/mwiBnx4nr1w},
}

@inproceedings{kang2018understanding,
  abbr={UbiComp},
  title={Understanding Customers' Interests in the Wild},
  author={Kang, Soowon and Kim, Auk and Lee, Jemin and Shin, Ikhee and Lee, Uichin},
  booktitle={Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers (Poster)},
  pages={90--93},
  year={2018},
  pdf = {https://dl.acm.org/citation.cfm?id=3267625},
  poster = {SuggestBot_Poster_final.pdf},
}

@article{lee2018reducing,
  abbr={Hindawi},
  title={Reducing smartwatch users’ distraction with convolutional neural network},
  author={Lee, Jemin and Kwon, Jinse and Kim, Hyungshin and others},
  journal={Mobile Information Systems, vol. 2018, Article ID 7689549, 9 pages, 15 Mar. 2018 (special issue in Advances in Personalized Mobile Services). (impact factor(JCR18): <span class="label label-danger">1.635</span>), ISSN: 1574-017X (print), 1875-905X(online)},
  volume={2018},
  year={2018},
  publisher={Hindawi},
  pdf = {https://www.hindawi.com/journals/misy/aip/7689549/},
}

@article{lee2016qdroid,
  abbr={Hindawi},
  title={QDroid: Mobile application quality analyzer for app market curators},
  author={Lee, Jemin and Kim, Hyungshin},
  journal={Mobile Information Systems, vol. 2016, Article ID 1740129, 11 pages, 10 Oct. 2016. (impact factor(JCR15): <span class="label label-danger">1.462</span>), ISSN: 1574-017X (print), 1875-905X(online)},
  volume={2016},
  year={2016},
  publisher={Hindawi},
  pdf = {http://dx.doi.org/10.1155/2016/1740129},
  code = {https://github.com/leejaymin/QDroid},
}

@article{joe2017output,
  abbr={FGCS},
  title={Output-oriented power saving mode for mobile devices},
  author={Joe, Hyunwoo and Kim, Jungseok and Lee, Jemin and Kim, Hyungshin},
  journal={Future Generation Computer Systems, 6 Jun. 2016, ISSN 0167-739X.<br>(impact factor: <span class="label label-danger">2.430</span>, JCR-2015: <span class="label label-warning">Top 10%</span>, theory & methods category rank <span class="label label-warning">#11</span> out of 150)},
  volume={72},
  pages={49--64},
  year={2017},
  publisher={Elsevier},
  pdf = {http://dx.doi.org/10.1016/j.future.2016.05.012},
  video = {https://youtu.be/SOgCiU3rC34},
}

@article{lee2014automated,
  abbr={IEEE TCE},
  title={Automated power model generation method for smartphones},
  author={Lee, Jemin and Joe, Hyunwoo and Kim, Hyungshin},
  journal={IEEE Transactions on Consumer Electronics},
  volume={60},
  number={2},
  pages={190--197},
  year={2014},
  publisher={IEEE},
  pdf = {http://dx.doi.org/10.1109/TCE.2014.6851993},
  code = {https://github.com/PowerLab/PowerDoctor},
}

@inproceedings{park2017emsoftco,
  abbr={HENND},
  title={Analysis of Hardware Resources in Distributed Learning (Poster)},
  author={Sihyeong Park and Jemin Lee and Hyungshin Kim},
  booktitle={In Proceedings of International Workshop on Highly Efficient Neural Networks Design (co-located with EMSOFT), pp. 1-4, Seoul, South Korea, 20 Oct. 2017.},
  year={2017},
  organization={IEEE}
}

@inproceedings{Jinse17s,
  abbr={IEEE IPIN},
  title={An Ultrasound-based Indoor Localiztion Using Gaussian ASK Modulation (WIP)},
  author={Jinse Kwon and Jemin Lee and Hyungshin Kim},
  booktitle={In Proceedings of International Conference on Indoor Positioning and Indoor Navigation, pp.1-4, Sapporo, Japan, 20 Sept. 2017.},
  year={2017},
  organization={IEEE},
  pdf = {http://www.ipin2017.org/ipinpapers/225/225.pdf}
}


@inproceedings{park2017a,
  abbr={IEMEK},
  title={Deep Learning Training on Distributed Embedded Systems (Poster)},
  author={Sihyeong Park and Jemin Lee and Hyungshin Kim},
  booktitle={In Proceedings of the 12th lEMEK Symposium on Embedded Technology, Busan, South Korea, 18-19 May, 2017.},
  year={2017},
  organization={IEMEK},
  pdf = {iset2017.pdf},
  slides = {2017_ISET_park.pdf},
}

@inproceedings{Jinyoung2017a,
  abbr={IoTDI},
  title={Extending App Pre-Launch Service with Emotion Context (Poster)},
  author={Jinyoung Choi and Jemin Lee and Hyungshin Kim},
  booktitle={In Proceedings of the 2nd ACM/IEEE International Conference on Internet-of-Things Design and Implementation (IoTDI’17) Adjunct, pp. 1-2, Pittsburgh, USA, 18-21 Apr. 2017.},
  year={2017},
  organization={ACM/IEEE},
  pdf = {http://dl.acm.org/citation.cfm?id=3057306},
  slides = {2017_IoTDI_choi_Poster.pdf},
}


@inproceedings{lee2016a,
  abbr={MobileHCI},
  title={Reducing Distraction of Smartwatch Users with Deep Learning},
  author={Jemin Lee and Jinse Kwon and Hyungshin Kim},
  booktitle={In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI'16) Adjunct pp. 948-953, Florence, Italy, 05-09 Sept. 2016.},
  year={2016},
  organization={ACM},
  pdf = {http://dl.acm.org/citation.cfm?id=2962662},
  slides = {Smarttention_2016_Slides.pdf},
}

@inproceedings{lee2013a,
  abbr={MobiSys},
  title={Framework for automated power estimation of Android applications (Poster)},
  author={Jemin Lee and Hyungshin Kim},
  booktitle={In Proceedings of the 11th annual international conference on Mobile Systems, Applications, and Services (<span class="label label-info">Mobisys'13</span>) Adjunct pp. 541-542, Taipei, Taiwan, Jun. 2013.},
  year={2013},
  organization={ACM},
  pdf = {http://dx.doi.org/10.1145/2462456.2465723},
  video = {http://youtu.be/jVffMVXG0KI},
}

@inproceedings{Vincent2012a,
  abbr={APSys},
  title={Energy Reservation Service for Smart Phone Application (Poster)},
  author={Vincent Dupre and Jemin Lee and Hyungshin Kim},
  booktitle={In Proceedings of 3rd ACM/SIGOPS Asia-Pacific Workshop on Systems (APSys'12), Seoul, South Korea, Jul. 2012.},
  year={2012},
  organization={ACM}
}

@inproceedings{lee2012a,
  abbr={ICCE},
  title={Smart Phone Power Model Generation Using Use Pattern Analysis},
  author={Jemin Lee and  Hyunwoo Joe and Hyungshin Kim},
  booktitle={In Proceedings of IEEE International Conference on Consumer Electronics (ICCE'12) pp. 412-413, Las Vegas, NV, USA, Jan. 2012.},
  year={2012},
  organization={IEEE},
  pdf = {http://dx.doi.org/10.1109/ICCE.2012.6161925},
  slides = {ICCE2012.pdf},
}


@inproceedings{jemin2011,
  abbr={EKC},
  title={Smartphone, where does the power go?},
  author={Jemin Lee and Hyunwoo Joe and Hyungshin Kim},
  booktitle={In Proceedings of EU Korea Conference on Science and Technology (EKC'11), Paris, France, Jul. 2011.},
  year={2011},
  organization={IEEE},
  pdf = {EKC2011_smartphone_fullpaper.pdf},
}

