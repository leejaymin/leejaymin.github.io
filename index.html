<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Efficient Computing Lab.</title> <meta name="author" content="Jemin Lee"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://leejaymin.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6C%65%65%6A%61%79%6D%69%6E@%65%74%72%69.%72%65.%6B%72" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/https://orcid.org/0000-0002-9332-3508" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=http://scholar.google.com/citations?user=BcVJExUAAAAJ&amp;hl=en" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/leejaymin" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/jemin-lee-7759aa76/" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://facebook.com/jaymin.lee.37/" title="Facebook" rel="external nofollow noopener" target="_blank"><i class="fab fa-facebook"></i></a> <a href="https://youtube.com/@user-mc7ns3pg7g" title="YouTube" rel="external nofollow noopener" target="_blank"><i class="fab fa-youtube"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Members</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Efficient Computing Lab. </h1> <p class="desc">The Efficient Computing Laboratory (ECL) is a part of <a href="https://www.ust.ac.kr/prog/campus/campus_eng/sub36_04/36/majorView.do?majorNo=71&amp;kind=information" rel="external nofollow noopener" target="_blank">Department of AI at UST ETRI Campus</a>. Gajeong-ro 218, Yuseong-gu, Daejoen South Korea.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/ust-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/ust-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/ust-1400.webp"></source> <img src="/assets/img/ust.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="ust.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>7-416 ETRI, Gajeong-ro 218,Yuseong-gu123, Daejeon, South Korea</p> </div> </div> <div class="clearfix"> <p>Welcome to the <code class="language-plaintext highlighter-rouge">Efficient Computing Lab.</code> We focus on energy efficiency, system optimization, user experience, and sustainable tech solutions. Our research interests are the followings:</p> <p>• Model Compression: Enhancing machine learning models’ efficiency through techniques like pruning, quantization, and knowledge distillation for better performance in resource-limited settings. <br> • AI Compiler: Developing optimized AI compilers to reduce computational power, energy use, and execution time, improving efficiency and sustainability.</p> <p>For detailed research areas and insights into graduate life, please refer to the following slides. Students interested in pursuing graduate studies are encouraged to contact me directly after following the application instructions provided in the slides.</p> <p>You can reach me at: leejaymin_at_etri_dot_re_dot_kr.</p> </div> <div class="google-slides-container"> <div class="google-slides"> <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRa6W-Ocv40YIrqT6Rzw6nNCuAogAivd3LDn4io-fIq73WQQJP3fOu63QWG8QNaz-0QE1k_10nD7zRV/embed?start=false&amp;loop=false&amp;delayms=30000" frameborder="0" width="700" height="500" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe> </div> </div> <h2><a href="/news/" style="color: inherit;">News</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Dec 23, 2025</th> <td> <a class="news-title" href="/news/UST%20Research%20Paper%20Award%20%E2%80%93%20Sehyeon%20Oh%20(ETRI%20Representative%20Student)/">Ust research paper award – sehyeon oh (etri representative student)</a> </td> </tr> <tr> <th scope="row">Dec 5, 2025</th> <td> <a class="news-title" href="/news/Sehyeon%20Oh%20Received%20the%20Undang%20Student%20Paper%20Award%20from%20KIPS/">Sehyeon oh received the undang student paper award from kips</a> </td> </tr> <tr> <th scope="row">Nov 12, 2025</th> <td> <em>IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers</em> was accepted at <a href="https://wacv2026.thecvf.com/" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026</code></a>! Round 2 acceptance rate was 41.1% (Round 1: 6.4%), and the overall acceptance rate reached 26.4%. Congratulations<img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Nov 9, 2025</th> <td> <em>Target-Aware Neural Network Execution via Compiler-Guided Pruning</em> was accepted at <a href="https://www.computer.org/csdl/journal/tm" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">IEEE Transactions on Mobile Computing (IEEE TMC)</code></a>. Congratulations<img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Sep 8, 2025</th> <td> <a href="https://www.sciencedirect.com/science/article/pii/S0167739X25004170" rel="external nofollow noopener" target="_blank">Efficient Dataflow-flexible DNN Accelerator</a> was accepted at <a href="https://www.sciencedirect.com/journal/future-generation-computer-systems" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Future Generation Computer Systems (FGCS)</code></a>. Congratulations<img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Jul 14, 2025</th> <td> <code class="language-plaintext highlighter-rouge">Luthier</code> was accepted at <a href="https://esweek.org/cases/" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">ACM CASES</code></a> (ESWeek, NRF BK21+ IF 2) and <code class="language-plaintext highlighter-rouge">ACM TECS</code>. Congratulations<img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Jul 12, 2025</th> <td> <code class="language-plaintext highlighter-rouge">Two</code> papers were accepted at <a href="https://iplab.dmi.unict.it/acvr2025/" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">ICCV 2025 Workshop on Assistive Computer Vision and Robotics</code></a>. Congratulations<img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">Selected Publications</a></h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#1E90FF"><a href="">IEEE TMC</a></abbr></div> <div id="cha2025targetaware" class="col-sm-8"> <div class="title">Target-Aware Neural Network Execution via Compiler-Guided Pruning</div> <div class="author"> JooHyoung Cha, <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a>, <em>Jemin Lee*</em>, <a href="https://netstech.org/sangtaeha/" rel="external nofollow noopener" target="_blank">Sangtae Ha</a>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing (to appear), Accepted, IF 9.2 Nov. 9, 2025</em>, Nov 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/11240555" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>모바일 기기는 이미지 분류나 음성 인식과 같은 다양한 목적을 위해 딥러닝 모델을 실행한다. 그러나 모바일 기기의 자원 제약으로 인해, 연구자들은 모델 프루닝(pruning)을 통해 경량화된 딥 뉴럴 네트워크(DNN) 모델을 만들거나, 컴파일러 최적화를 통해 효율적인 코드를 생성하는 데 주력해 왔다. 하지만 모델 압축과 컴파일러 자동 튜닝(auto-tuning)을 단순히 결합하는 방식은 특정 타깃 장치에서 가장 효율적인 모델을 만들지 못하는 경우가 많음이 관찰되었다. 이 문제를 해결하기 위해 우리는 CPrune을 제안한다. CPrune은 요구되는 정확도를 충족해야 하는 애플리케이션을 지원하기 위해, 타깃 장치 특화 효율적 실행을 위한 컴파일러 기반 정보 활용 모델 프루닝(compiler-informed model pruning) 기법이다. 또한 실제 배포 환경에서의 자원 또는 지연(latency) 제약을 고려하여, 우리는 RB-CPrune을 도입한다. RB-CPrune은 학습된 **지연 예측기(latency estimator)**를 활용해 반복적인 튜닝 과정을 제거한 예측 기반(prdictive) 변형 기법이다. CPrune은 컴파일러 튜닝 과정에서 구축된 서브그래프의 구조적 정보를 기반으로 프루닝을 수행함으로써 경량 DNN 모델을 생성한다. 실험 결과, CPrune은 정확도 요구 조건을 충족하면서도 최첨단 TVM auto-tune 대비 최대 2.73배 빠른 DNN 실행 속도를 달성함을 보여주었다.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">CASES</abbr><abbr class="badge award">Artifacts</abbr> </div> <div id="cases25" class="col-sm-8"> <div class="title">Luthier: Bridging Auto-Tuning and Vendor Libraries for Efficient Deep Learning Inference<span class="acm-badges" style="margin-left:8px; white-space:nowrap;"> <img src="/assets/img/badges/artifacts_available_v1_1.png" alt="Artifacts Available" style="height:1em; vertical-align:baseline; margin-right:4px;"> <img src="/assets/img/badges/artifacts_evaluated_functional_v1_1.png" alt="Artifacts Evaluated – Functional" style="height:1em; vertical-align:baseline; margin-right:4px;"> </span> </div> <div class="author"> <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, JooHyoung Cha, Sehyeon Oh, <a href="https://scholar.google.com/citations?user=wvSMjuUAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Misun Yu</a>, <a href="https://ksp.etri.re.kr/ksp/user/f9caab48-4826-4c7f-b9e8-4fbb8916fc10" rel="external nofollow noopener" target="_blank">Jeman Park</a>, and <em>Jemin Lee*</em> </div> <div class="periodical"> <em>In ACM International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (ESWEEK CASES 2025) (NRF BK21+ IF: 2, Acceptance Rate 28.2% (20 papers accepted out of 71 submitted)) and ACM Transactions on Embedded Computing Systems (TECS) Vol. 24, No. 5s, pp. 1–23 ISSN:1539-9087, September 29, 2025.</em>, Sep 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/10.1145/3759916" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/Luthier" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/luthier_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/luthier_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3759916"></span> <span class="__dimensions_badge_embed__" data-doi="10.1145/3759916" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>최근 딥러닝 컴파일러는 텐서 프로그래밍에서 최적의 커널 구성을 처음부터 탐색하는 자동 튜닝 방식을 주로 채택하는데, 이는 작업당 수십 시간이 소요되며 비대칭 멀티코어 프로세서에서의 병렬 컴퓨팅에 필수적인 최적화 요소를 간과합니다. 한편 하드웨어 벤더의 수동 최적화 추론 라이브러리는 높은 성능을 제공하지만 신흥 모델에 필요한 유연성과 자동화가 부족합니다. 이러한 격차를 해소하기 위해 우리는 기존 추론 라이브러리에서 최적의 커널을 선별하여 탐색 공간을 크게 축소하고, 비용 모델 기반 프로파일링을 활용해 병렬 컴퓨팅에 가장 효율적인 작업 부하 분배를 신속히 결정하는 Luthier를 제안합니다. 그 결과 Luthier는 ArmNN, AutoTVM, Ansor, ONNXRuntime, TFLite 대비 평균 튜닝 시간을 95% 단축하면서, CPU와 GPU 모두에서 컨볼루션 기반 비전 모델과 트랜스포머 기반 언어 모델(BERT, GPT)에서 최대 2.0배 빠른 실행 속도를 달성합니다. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IJCAI</abbr></div> <div id="lee25ijcai" class="col-sm-8"> <div class="title">Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://sihyeong.github.io/" rel="external nofollow noopener" target="_blank">Sihyeong Park</a>, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, Jihun Oh, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon*</a> </div> <div class="periodical"> <em>In International Joint Conferences on Artificial Intelligence (IJCAI) Aug. 22, 2025, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19.3%</span> (1042 papers accepted out of 5404 submitted).</em>, Aug 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.24963/ijcai.2025/902" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/ones-ai/eval-quant-llms" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>양자화는 대규모 및 소규모 언어 모델의 비용 효율적 배포를 위한 유망한 해결책으로 주목받고 있습니다. 그러나 기존 연구 대부분은 퍼플렉시티나 기초 지식 작업에 국한되어 있으며 Llama-3.3과 같은 최신 모델에 대한 포괄적 평가가 부족했습니다. 본 논문에서는 10억에서 4050억 매개변수에 이르는 명령어 학습 모델을 대상으로 13개 데이터셋에 걸쳐 4가지 양자화 기법을 적용하여 포괄적 평가를 수행합니다. 우리의 연구 결과는 다음과 같다: (1) 양자화 모델은 일반적으로 더 작은 FP16 기준 모델을 능가하지만, 명령어 수행 및 환각 탐지에서는 종종 어려움을 겪는다; (2) FP8은 모든 작업에서 가장 견고한 옵션으로 꾸준히 나타났으며, 가중치 전용 양자화에서는 AWQ가 GPTQ보다 우수한 성능을 보이는 경향이 있다; (3) 소규모 모델은 4비트 양자화 시 심각한 정확도 하락을 겪을 수 있는 반면, 70B 규모 모델은 안정적인 성능을 유지한다; (4) 특히, 어려운 작업이 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 모델의 본질적 약점을 증폭시키기보다는 가려진 부분을 드러낸다는 점을 시사한다. 4비트 양자화 시 심각한 정확도 하락을 보일 수 있으나, 70B 규모 모델은 안정적인 성능을 유지함; (4) 특히 어려운 과제가 항상 가장 큰 정확도 손실을 보이는 것은 아니며, 이는 양자화가 단순히 과제 난이도와 상관관계를 가지는 것이 아니라 모델의 내재적 약점을 증폭시킨다는 점을 시사함; (5) LLM 기반 평가 도구(MTBench)는 코딩 및 STEM 과제에서 상당한 성능 저하를 강조하지만, 추론에서는 가끔 개선을 보고함.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LCTES</abbr></div> <div id="lectes25" class="col-sm-8"> <div class="title">Multi-Level Machine Learning-Guided Autotuning for Efficient Code Generation on a Deep Learning Accelerator</div> <div class="author"> JooHyoung Cha, Munyoung Lee, <a href="https://scholar.google.com/citations?user=WbXEt40AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Jinse Kwon</a>, <em>Jemin Lee</em>, and <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a> </div> <div class="periodical"> <em>In The 26th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES) Jun. 17, 2025, To appear, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">38%</span> (16 papers accepted out of 42 submitted).</em>, Jun 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3735452.3735538" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>딥 러닝 모델의 복잡성 증가는 특히 딥 러닝 가속기를 위한 특수 하드웨어 및 소프트웨어 최적화를 필요로 합니다. 기계 학습 기반 자동 튜닝 방법이 수동 작업을 줄이는 유망한 해결책으로 부상했지만, 템플릿 기반 및 템플릿 프리 접근법 모두 유효하지 않은 구성 프로파일링으로 인해 튜닝 시간이 길어지는 문제점을 안고 있으며, 이는 런타임 오류로 이어질 수 있습니다. 이 문제를 해결하기 위해 효율성과 견고성을 개선하도록 설계된 다단계 머신 러닝 기반 자동 튜닝 기술인 ML2Tuner를 제안합니다. ML2Tuner는 두 가지 핵심 아이디어를 도입합니다: (1) 프로파일링 전에 무효한 구성을 걸러내는 유효성 예측 모델, (2) 컴파일 과정에서 추출된 숨겨진 특징을 활용하는 고급 성능 예측 모델입니다. 확장된 VTA 가속기에서의 실험 결과, ML2Tuner는 TVM 유사 접근법이 요구하는 샘플의 12.3%만을 사용하여 동등한 성능 향상을 달성하며, 무효 프로파일링 시도를 평균 60.8% 감소시킵니다. 이는 무효 구성을 걸러내어 자동 튜닝 성능을 향상시킬 수 있는 잠재력을 보여줍니다.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IROS</abbr></div> <div id="VisualIROS2024" class="col-sm-8"> <div class="title">Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation</div> <div class="author"> Joonhyung Lee, Sangbeom Park, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://www.linkedin.com/in/minwook-ahn-4a7b6433/?originalSubdomain=kr" rel="external nofollow noopener" target="_blank">Minwook Ahn</a>, and <a href="https://scholar.google.co.kr/citations?user=T3-0OQ8AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Sungjoon Choi</a> </div> <div class="periodical"> <em>In 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2403.11513" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/joonhyung-lee/vpi" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://joonhyung-lee.github.io/vpi/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DAA520"><a href="">ECCV</a></abbr></div> <div id="kim2022cprune" class="col-sm-8"> <div class="title">CPrune: Compiler-informed model pruning for efficient target-aware DNN execution</div> <div class="author"> <a href="https://scholar.google.com/citations?user=A74mynoAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">T. Kim</a>, <a href="https://www.linkedin.com/in/yongin-kwon-17089289/" rel="external nofollow noopener" target="_blank">Yongin Kwon</a>, <em>Jemin Lee</em>, <a href="https://scholar.google.com/citations?user=vxnZtD0AAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Taeho Kim</a>, and <a href="https://netstech.org/sangtaeha/" rel="external nofollow noopener" target="_blank">Sangtae Ha</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV), pp.651–667, Oct. 23-27, 2022, NRF BK21+ IF: 2, Acceptance Rate <span class="label label-warning">28%</span> (1,650 papers accepted out of 5,803 submitted), doi: https://doi.org/10.1007/978-3-031-20044-1_37</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-20044-1_37" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/taehokim20/CPrune" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>모바일 기기에서는 이미지 분류, 음성 인식 등 다양한 목적을 위해 딥러닝 모델이 실행된다. 그러나 모바일 기기의 자원 제약으로 인해 연구자들은 모델 프루닝을 활용하여 경량화된 DNN 모델을 만들거나, 컴파일러 최적화를 통해 효율적인 코드를 생성하는 것에 주로 집중해 왔다. 놀랍게도, 우리는 모델 압축과 컴파일러 자동 튜닝(auto-tuning)을 단순히 결합하는 방식이 특정 타깃 장치에서 가장 효율적인 모델을 생성하지 못하는 경우가 많다는 사실을 발견했다. 이 문제를 해결하기 위해, 우리는 CPrune을 제안한다. CPrune은 목표 정확도를 충족해야 하는 애플리케이션을 지원하기 위해 타깃 장치에 최적화된 DNN 실행을 가능하게 하는 컴파일러 기반 정보 활용 프루닝(compiler-informed model pruning) 기법이다. CPrune은 컴파일러 튜닝 과정에서 생성되는 서브그래프의 구조적 정보를 기반으로 프루닝을 수행하여 경량화된 DNN 모델을 만든다. 실험 결과, CPrune은 정확도 요구 조건을 충족하면서도 최첨단 TVM auto-tune 대비 최대 2.73배 빠른 DNN 실행 속도를 달성하였다.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#1E90FF"><a href="">IEEE TMC</a></abbr></div> <div id="lee2019pass" class="col-sm-8"> <div class="title">PASS: Reducing redundant notifications between a smartphone and a smartwatch for energy saving</div> <div class="author"> <em>Jemin Lee</em>, <a href="https://ic.kaist.ac.kr/members" rel="external nofollow noopener" target="_blank">Uichin Lee</a>, and <a href="https://www.linkedin.com/in/hyungshin-kim-0964a933/" rel="external nofollow noopener" target="_blank">Hyungshin Kim</a> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing,(impact factor: 5.538, JCR20: Top 17%, telecommunications rank #16 out of 91), ISSN: 1536-1233, doi: https://doi.org/10.1109/TMC.2019.2930506</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TMC.2019.2930506" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/leejaymin/nCollector" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC143C"><a href="">MobiCom</a></abbr></div> <div id="kang2019fire2" class="col-sm-8"> <div class="title">Fire in your hands: Understanding thermal behavior of smartphones</div> <div class="author"> <a href="https://scholar.google.com/citations?user=B9HMz0EAAAAJ&amp;hl=ko" rel="external nofollow noopener" target="_blank">Soowon Kang</a>, Hyeonwoo Choi, Sooyoung Park, <a href="http://cjpark.xyz/" rel="external nofollow noopener" target="_blank">Chunjong Park</a>, <em>Jemin Lee</em>, <a href="https://ic.kaist.ac.kr/members" rel="external nofollow noopener" target="_blank">Uichin Lee</a>, and <a href="https://sites.google.com/site/wewantsj/" rel="external nofollow noopener" target="_blank">Sung-Ju Lee</a> </div> <div class="periodical"> <em>In The 25th Annual International Conference on Mobile Computing and Networking, pp. 1-16, Los Cabos, Mexico, 21-25 Oct. 2019, NRF BK21+ IF: 4, Acceptance Rate <span class="label label-warning">19%</span> (55 papers accepted out of 290 submitted).</em>, Oct 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://dl.acm.org/citation.cfm?id=3300128" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://nmsl.kaist.ac.kr/projects/thermal/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Jemin Lee. Last updated: December 27, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>